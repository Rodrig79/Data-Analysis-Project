{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2E1jbS4ZluC",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-learn) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from seaborn) (1.19.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from seaborn) (3.3.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (7.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (0.14.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-plot in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-plot) (3.3.0)\n",
      "Requirement already satisfied: joblib>=0.10 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-plot) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-plot) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-plot) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from scikit-learn>=0.18->scikit-plot) (2.1.0)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from statsmodels) (1.19.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: pandas>=0.21 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from statsmodels) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2020.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#If you need to install in modules in jupyter notebook \n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "%pip install matplotlib \n",
    "%pip install seaborn \n",
    "%pip install graphviz\n",
    "%pip install scikit-plot   \n",
    "%pip install statsmodels   \n",
    "\n",
    "\n",
    "#Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import datetime # Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scikitplot as skplt\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.linear_model import LinearRegression\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvsV2RSPapC6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#changes the output for the print statements\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtW9LfInZ_x2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Pull \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Rodrig79/Machine-Learning-Data-Analysis-Project/master/rawData/pokemon.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-792-1225af154368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Data Cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mega'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#removed pokemon with \"Mega\" in it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Type 1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Type 2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Generation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Removed columns with names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.2/libexec/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Name'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#Data Cleaning\n",
    "df = df[~df.Name.str.contains('Mega')] #removed pokemon with \"Mega\" in it\n",
    "df = df.drop(columns = [\"Name\",\"Type 1\",\"Type 2\",\"#\",\"Generation\"]) #Removed columns with names\n",
    "\n",
    "#normalization\n",
    "X = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df=pd.DataFrame(x_scaled, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Splitting dataset to x and y\n",
    "y = df.Attack\n",
    "X = df[['Defense','HP','Sp. Atk','Sp. Def','Speed']]\n",
    "# X = df.HP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiVariate  Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiVariateLinearRegression(X,y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60)\n",
    "  regr = LinearRegression()\n",
    "  regr.fit(X, y)\n",
    "  print('Intercept: \\n', regr.intercept_)\n",
    "  print('Coefficients: \\n', regr.coef_)\n",
    "  kf = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "  kf.get_n_splits(X)\n",
    "  for train_index, test_index in kf.split(X):\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_train)\n",
    "  print(\"coefficient of determination score\",r2_score(y_train,y_pred))\n",
    "  print(\"mean squared error\",mean_squared_error(y_train,y_pred,squared =False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 0.015933105582873475\n",
      "Coefficients: \n",
      " [ 0.57361907  0.53694675  0.17710785 -0.37966666  0.29630742]\n",
      "coefficient of determination score 0.45680280610639856\n",
      "mean squared error 0.13384242318492964\n"
     ]
    }
   ],
   "source": [
    "MultiVariateLinearRegression(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.HP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Mini Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21345299 0.72120008]\n"
     ]
    }
   ],
   "source": [
    "X_b = np.c_[np.ones((751, 1)), X]  # add x0 = 1 to each instance\n",
    "\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "\n",
    "print(theta_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21345299, 1.65585316])"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]  # add x0 = 1 to each instance\n",
    "\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10866883 -1.70876764]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.72854204, -1.21339713])"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 10\n",
    "m = 100\n",
    "theta = np.random.randn(2, 1)\n",
    "theta = np.squeeze(np.asarray(theta))\n",
    "print (theta)\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51834726,  0.44668995,  0.35114687,  0.54701019,  0.45624426,\n",
       "        0.36070118,  0.52312442,  0.45146711,  0.35592403,  0.51834726,\n",
       "        0.49446149,  0.44668995,  0.54223303,  0.51834726,  0.42280418,\n",
       "        0.54223303,  0.43235849,  0.33681541,  0.59000457,  0.47057572,\n",
       "        0.54223303,  0.42280418,  0.5661188 ,  0.44668995,  0.5661188 ,\n",
       "        0.44668995,  0.49446149,  0.37503264,  0.47057572,  0.39891841,\n",
       "        0.30337533,  0.51357011,  0.4419128 ,  0.34636972,  0.39891841,\n",
       "        0.27948956,  0.55178734,  0.38458695,  0.18394648,  0.06451763,\n",
       "        0.54223303,  0.37503264,  0.51834726,  0.44668995,  0.37503264,\n",
       "        0.5661188 ,  0.44668995,  0.44668995,  0.39891841,  0.68554766,\n",
       "        0.5661188 ,  0.54223303,  0.42280418,  0.49446149,  0.35114687,\n",
       "        0.54223303,  0.42280418,  0.47057572,  0.30337533,  0.54223303,\n",
       "        0.42280418,  0.30337533,  0.61389034,  0.54223303,  0.47057572,\n",
       "        0.39891841,  0.35114687,  0.30337533,  0.49446149,  0.42280418,\n",
       "        0.35114687,  0.54223303,  0.35114687,  0.54223303,  0.47057572,\n",
       "        0.35114687,  0.49446149,  0.42280418,  0.30337533,  0.27948956,\n",
       "        0.61389034,  0.49446149,  0.48490718,  0.5661188 ,  0.44668995,\n",
       "        0.42280418,  0.30337533,  0.35114687,  0.23171802,  0.59000457,\n",
       "        0.49446149,  0.59000457,  0.51834726,  0.44668995,  0.5661188 ,\n",
       "        0.44668995,  0.3272611 ,  0.59000457,  0.47057572,  0.54223303,\n",
       "        0.44668995,  0.44668995,  0.27948956,  0.49446149,  0.44668995,\n",
       "        0.49446149,  0.49446149,  0.30337533,  0.54223303,  0.42280418,\n",
       "        0.35114687,  0.23171802, -0.46096932,  0.42280418,  0.23171802,\n",
       "        0.59000457,  0.47057572,  0.51834726,  0.35114687,  0.59000457,\n",
       "        0.44668995,  0.54223303,  0.39891841,  0.42280418,  0.42280418,\n",
       "        0.42280418,  0.42280418,  0.37503264,  0.63777611,  0.27948956,\n",
       "        0.11228917,  0.5040158 ,  0.47057572,  0.11228917,  0.42280418,\n",
       "        0.42280418,  0.42280418,  0.5661188 ,  0.39891841,  0.59000457,\n",
       "        0.44668995,  0.35114687, -0.03102545,  0.30337533,  0.30337533,\n",
       "        0.30337533,  0.53745588,  0.4419128 ,  0.29859818,  0.22694087,\n",
       "        0.25560379,  0.51834726,  0.44668995,  0.54701019,  0.45624426,\n",
       "        0.36070118,  0.49446149,  0.42280418,  0.3272611 ,  0.5661188 ,\n",
       "        0.3272611 ,  0.44668995,  0.25560379,  0.54223303,  0.47057572,\n",
       "        0.54223303,  0.39891841,  0.3272611 ,  0.37503264,  0.13617494,\n",
       "        0.63777611,  0.49446149,  0.30337533,  0.5661188 ,  0.47057572,\n",
       "        0.54223303,  0.42280418,  0.47057572,  0.39891841,  0.30337533,\n",
       "        0.37503264,  0.39891841,  0.25560379,  0.39891841,  0.30337533,\n",
       "        0.5661188 ,  0.47057572,  0.37503264,  0.47057572,  0.59000457,\n",
       "        0.37503264,  0.42280418,  0.47057572,  0.27948956,  0.42280418,\n",
       "        0.27948956,  0.44668995,  0.27948956,  0.44668995,  0.5040158 ,\n",
       "       -0.17434008,  0.39891841,  0.49446149,  0.37503264,  0.25560379,\n",
       "        0.42280418,  0.37503264,  0.44668995,  0.30337533,  0.42280418,\n",
       "        0.39891841,  0.63777611,  0.35114687,  0.47057572,  0.44668995,\n",
       "        0.30337533,  0.54223303,  0.49446149,  0.49446149,  0.25560379,\n",
       "        0.47057572,  0.5661188 ,  0.37503264,  0.51834726,  0.42280418,\n",
       "        0.42280418,  0.51834726,  0.37503264,  0.37503264,  0.30337533,\n",
       "        0.30337533,  0.3272611 ,  0.38458695,  0.47057572,  0.5661188 ,\n",
       "        0.49446149,  0.51834726,  0.51834726,  0.51834726,  0.27948956,\n",
       "       -0.48485509,  0.30337533,  0.18394648,  0.25560379,  0.49446149,\n",
       "        0.39891841,  0.25560379,  0.22694087,  0.22694087,  0.25560379,\n",
       "        0.54223303,  0.49446149,  0.39891841,  0.51834726,  0.44668995,\n",
       "        0.35114687,  0.49446149,  0.39891841,  0.25560379,  0.5661188 ,\n",
       "        0.39891841,  0.55178734,  0.36070118,  0.51834726,  0.49446149,\n",
       "        0.44668995,  0.49446149,  0.44668995,  0.54223303,  0.44668995,\n",
       "        0.35114687,  0.54223303,  0.39891841,  0.30337533,  0.54223303,\n",
       "        0.44668995,  0.54223303,  0.44668995,  0.59955888,  0.55178734,\n",
       "        0.40847272,  0.54223303,  0.39891841,  0.44668995,  0.44668995,\n",
       "        0.44668995,  0.35114687,  0.01674609,  0.58522742,  0.4419128 ,\n",
       "        0.72854204,  0.42758134,  0.33203825,  0.23649517,  0.3893641 ,\n",
       "        0.04540901,  0.49446149,  0.59000457,  0.49446149,  0.39891841,\n",
       "        0.49446149,  0.49446149,  0.49446149,  0.44668995,  0.39891841,\n",
       "        0.59000457,  0.44668995,  0.54223303,  0.39891841,  0.44668995,\n",
       "        0.44668995,  0.42280418,  0.42280418,  0.49446149,  0.39891841,\n",
       "        0.25560379,  0.51834726,  0.39891841,  0.11228917, -0.07879699,\n",
       "        0.44668995,  0.39891841,  0.39891841,  0.44668995,  0.35114687,\n",
       "        0.44668995,  0.51834726,  0.49446149,  0.35114687,  0.49446149,\n",
       "        0.39891841,  0.51834726,  0.37503264,  0.38458695,  0.38458695,\n",
       "        0.39891841,  0.39891841,  0.49446149,  0.20783225,  0.52790157,\n",
       "        0.43235849,  0.54223303,  0.44668995,  0.41802703,  0.32248395,\n",
       "        0.51834726,  0.37503264,  0.63777611,  0.27948956,  0.39891841,\n",
       "        0.44668995,  0.52312442,  0.42758134,  0.63777611,  0.54223303,\n",
       "        0.26038094,  0.42280418,  0.42280418,  0.27948956,  0.49446149,\n",
       "        0.35114687,  0.39891841,  0.30337533,  0.20783225,  0.5661188 ,\n",
       "        0.47057572,  0.47057572,  0.25560379,  0.52790157,  0.51834726,\n",
       "        0.42280418,  0.27948956,  0.54223303,  0.44668995,  0.35114687,\n",
       "        0.35114687,  0.35114687,  0.35114687,  0.35114687,  0.35114687,\n",
       "        0.25560379,  0.25560379,  0.25560379,  0.25560379,  0.23171802,\n",
       "        0.25560379,  0.49446149,  0.49446149,  0.49446149,  0.49446149,\n",
       "        0.47057572,  0.37503264,  0.27948956,  0.52312442,  0.42758134,\n",
       "        0.37025549,  0.48013003,  0.42758134,  0.33203825,  0.54223303,\n",
       "        0.47057572,  0.3272611 ,  0.45146711,  0.35592403,  0.5565645 ,\n",
       "        0.36547833,  0.51834726,  0.44668995,  0.35114687,  0.54223303,\n",
       "        0.44668995,  0.41324987,  0.26993525,  0.59000457,  0.44668995,\n",
       "        0.54223303,  0.44668995,  0.44668995,  0.44668995,  0.39891841,\n",
       "        0.59000457,  0.39891841,  0.44668995,  0.47057572,  0.3272611 ,\n",
       "        0.51834726,  0.39891841,  0.37025549,  0.2030551 ,  0.37503264,\n",
       "        0.30337533,  0.01674609,  0.47057572,  0.42280418,  0.44668995,\n",
       "        0.25560379,  0.49923865,  0.39414126,  0.51834726,  0.43235849,\n",
       "        0.24127233,  0.46102141,  0.41324987,  0.49446149,  0.63777611,\n",
       "        0.25560379,  0.37025549,  0.49446149,  0.45624426,  0.40847272,\n",
       "        0.21738656,  0.0884034 ,  0.54223303,  0.39891841,  0.40847272,\n",
       "        0.21738656,  0.54223303,  0.39891841,  0.5040158 ,  0.33681541,\n",
       "        0.3798098 ,  0.49923865,  0.40369557,  0.51834726,  0.44668995,\n",
       "        0.30337533,  0.39891841,  0.39891841,  0.20783225,  0.18394648,\n",
       "        0.25560379,  0.37503264,  0.37503264,  0.3272611 ,  0.32248395,\n",
       "        0.42280418,  0.42280418,  0.37503264,  0.20783225,  0.3272611 ,\n",
       "        0.40847272,  0.44668995,  0.51834726,  0.39891841,  0.49446149,\n",
       "        0.49446149,  0.49446149,  0.49446149,  0.49446149,  0.49446149,\n",
       "        0.37503264,  0.35114687,  0.37503264,  0.25560379,  0.30337533,\n",
       "        0.29859818,  0.20783225,  0.01674609,  0.01674609,  0.16006071,\n",
       "        0.35114687,  0.25560379,  0.39891841,  0.25560379,  0.25560379,\n",
       "        0.16006071,  0.25560379,  0.51834726,  0.44668995,  0.37503264,\n",
       "        0.42280418,  0.30337533,  0.20783225,  0.47057572,  0.37503264,\n",
       "        0.27948956,  0.51834726,  0.44668995,  0.51834726,  0.42280418,\n",
       "        0.3272611 ,  0.53745588,  0.42758134,  0.49446149,  0.37503264,\n",
       "        0.49446149,  0.37503264,  0.49446149,  0.37503264,  0.37025549,\n",
       "        0.17916932,  0.49446149,  0.43713564,  0.35114687,  0.51834726,\n",
       "        0.37503264,  0.47057572,  0.39891841,  0.3272611 ,  0.47057572,\n",
       "        0.41324987,  0.44668995,  0.20783225,  0.24127233,  0.37503264,\n",
       "        0.3272611 ,  0.23171802,  0.49446149,  0.37503264,  0.23171802,\n",
       "        0.16006071,  0.37503264,  0.51834726,  0.47057572,  0.37503264,\n",
       "        0.59000457,  0.54223303,  0.44668995,  0.54223303,  0.44668995,\n",
       "        0.51834726,  0.39891841,  0.39891841,  0.49446149,  0.44668995,\n",
       "        0.27948956,  0.39891841,  0.23171802,  0.23171802,  0.37503264,\n",
       "        0.49446149,  0.39891841,  0.49446149,  0.42280418,  0.3893641 ,\n",
       "        0.55178734,  0.45624426,  0.47535288,  0.3798098 ,  0.47057572,\n",
       "        0.37503264,  0.49446149,  0.35114687,  0.54223303,  0.44668995,\n",
       "        0.47057572,  0.37503264,  0.51834726,  0.44668995,  0.39891841,\n",
       "        0.51834726,  0.42280418,  0.20783225,  0.43713564,  0.37503264,\n",
       "        0.56134165,  0.48968434,  0.39414126,  0.44668995,  0.35114687,\n",
       "        0.47057572,  0.49446149,  0.39891841,  0.40369557,  0.18872363,\n",
       "        0.47057572,  0.25560379, -0.05491122,  0.49446149,  0.39891841,\n",
       "        0.52312442,  0.3798098 ,  0.54223303,  0.44668995,  0.44668995,\n",
       "        0.5661188 ,  0.42280418,  0.3272611 ,  0.47057572,  0.37503264,\n",
       "        0.49446149,  0.44668995,  0.44668995,  0.51357011,  0.41802703,\n",
       "        0.37025549,  0.47057572,  0.27948956,  0.39891841,  0.49446149,\n",
       "        0.35114687,  0.2126094 ,  0.51834726,  0.42280418,  0.36547833,\n",
       "        0.45146711,  0.30815248,  0.51834726,  0.42280418,  0.27948956,\n",
       "        0.39891841,  0.25560379,  0.39891841,  0.20783225,  0.3272611 ,\n",
       "        0.45624426,  0.48490718,  0.3893641 ,  0.29382102,  0.47057572,\n",
       "        0.3272611 ,  0.29859818,  0.29859818,  0.29859818,  0.35592403,\n",
       "        0.35592403,  0.35592403,  0.35592403,  0.25560379,  0.25560379,\n",
       "        0.30815248,  0.30815248,  0.13617494,  0.13617494,  0.13617494,\n",
       "        0.29859818,  0.29859818,  0.25560379,  0.25560379,  0.39414126,\n",
       "        0.46579857,  0.4419128 ,  0.31292964,  0.54223303,  0.45146711,\n",
       "        0.37503264,  0.53745588,  0.47535288,  0.3893641 ,  0.55178734,\n",
       "        0.3272611 ,  0.51834726,  0.43713564,  0.36070118,  0.55178734,\n",
       "        0.51834726,  0.35114687,  0.43713564,  0.32248395,  0.52312442,\n",
       "        0.47535288,  0.36070118,  0.41802703,  0.14572925,  0.41324987,\n",
       "        0.27948956,  0.37503264,  0.43713564,  0.3798098 ,  0.3798098 ,\n",
       "        0.51834726,  0.45146711,  0.44668995,  0.44668995,  0.36070118,\n",
       "        0.25082664,  0.43713564,  0.34159256,  0.48013003,  0.32248395,\n",
       "        0.53267873,  0.3893641 ,  0.49446149,  0.42280418,  0.49446149,\n",
       "        0.39414126,  0.52312442,  0.43713564,  0.45624426,  0.34159256,\n",
       "        0.36547833,  0.14572925,  0.27948956,  0.36070118,  0.41324987,\n",
       "        0.49446149,  0.51834726,  0.40847272,  0.30337533,  0.46102141,\n",
       "        0.52790157,  0.3272611 ,  0.49923865,  0.52312442,  0.47535288,\n",
       "        0.45146711,  0.42280418,  0.47057572,  0.37503264,  0.3272611 ,\n",
       "        0.47057572,  0.27948956,  0.54223303,  0.3272611 ,  0.13139778,\n",
       "        0.13139778,  0.21738656,  0.49446149,  0.35114687,  0.35114687,\n",
       "        0.35114687])"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_bgd = []\n",
    "\n",
    "def plot_gradient_descent(theta, eta, theta_path=None):\n",
    "    m = len(X_b)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    n_iterations = 1000\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration < 10:\n",
    "            y_predict = X_new_b.dot(theta)\n",
    "            style = \"b-\" if iteration > 0 else \"r--\"\n",
    "            plt.plot(X_new, y_predict, style)\n",
    "            \n",
    "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "        theta = theta - eta * gradients\n",
    "        if theta_path is not None:\n",
    "            theta_path.append(theta)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 240, 0, 350])\n",
    "    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure gradient_descent_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAekUlEQVR4nO3dfbRd9V3n8fcHgqGSxAZIKVMdIqyWaKqhcitrplZaO5ZSnzqiYym6ih3Ah8VoFzNqHUNhChUVR2d1tFUYKFChrXUoto4L17QCjp2iXmrpkEIZsQZZhRpqDEmAUOh3/jj7rvlxexNucs/DPve+X2vtdc/Zv733+d6T88n63v10UlVIkiRJGjhs0gVIkiRJfWKDLEmSJDVskCVJkqSGDbIkSZLUsEGWJEmSGjbIkiRJUsMGWZIkSWrYIEuSJEkNG2QdsiTfkOQPkuxK8liSm5P882Gun+SHkvz3JNuTPJHkc0muSLJ2+L+RtPwtJbdJvj7Jf03yySSPJ6kkG0dcsrRiLDGfr+oyOX/6pxGXvSzFb9LToUjytcDdwD5gK1DA5cDXAt9aVXuHsX6SO4EHgT8EHgJeBlwK3Af8y6r6yrB/N2m5GkJuXwV8ELgLOBx4LfCNVfV3IytaWiGGlM/bgJ8B/qoZerqqZkdQ8rK2atIFaGqdD5wInFxVfwOQ5DPA/wV+AviNIa3/fVW1o1nvjiT/CFwPvAr406H8NtLKsNTc/llVHdetdx6DBlnScCw1n3Purao7R1PiyuEpFstEkq3dKQgvTfKRJLuTfCHJLyfJCF7y+4E750IMUFWfBz4B/MCw1p/XHM+Z+8v4RYdQt9Qb05Zbj9hoJZm2fGq4bJCXj5cBTwLXArcA/5pBqH4R+Pb5C2dg1SKmw/fzepuBexaYvw345kXUu5T1T+9+3ruI15H6bNpyK60k05rPG5M8k+RLSW5a7DnMejZPsVg+TgH2AmdW1ZcAkjwI/BCwEfiLecufzuBcpedyB4NTGeY7Gti5wPx/BNYvYruHtH6SFwHvAD7mOVVaBk5hunIrrSSnMF353AX85277jzFo8P8j8MkkL6uqf1jENtSxQV4GkqwDvhG4eC7EnSO7nwudpnAX8PJFbH73EssbmiRrGFys9zTw4xMuR1qSlZJbaRpNYz6r6q+Bv25m3ZHkz4C/ZHDh3tZRvO5yZYO8PJwCBPjYvPnf2v38Pwusswf49CK2vb/bnOxk4b9o9/cX8JLWT/I84KMMLmA4vaoeWsRrSH12CtOXW2mlOIVlkM+q+lSS+1lc466G5yAvDy8DngE+M2/+twF/v58L3U4HvryI6eP7ec1tDM6Xmu+bgc8uouZFr5/kCOAPgBng9VW10H9M0rSZxtxKK8Vyy6f39D1I7kFeHk4BPldVT8ybfyqDQz4LWeqhoI8Av57kxKr6W4DuCwNeAbxtEdtd1PpJDgNuBL4L+F5vXaNl5BSmL7fSSnEKyyCfSWaAkxnsZNJB8ItCloEknwbuqaofbeaFwQn7v1ZVl4/gNY9icEPzJ/j/NzS/DFjL4Ibme7rlTmfw1/JbquqGQ1j/PcBPAu8E/mheGQ95qoWm1TTmthv7oe7haxhk86cZnI+5o6ruGHbN0iRMYz6T3Ah8HvgU8E8M9oL/IvA48G1V9eiwa17OPMViyiX5GgaHXz49b+glDEK1v790l6T7Rp/vAu4H3sdgL+/nge+aC/FciQy+ceuwQ1z/zO7nLwGfnDedN9zfShqPac1t50Pd9JPd83d3z//TKGqWxm2K83kPg3spvxf4E+CtwM3AaTbHB889yMtUkrOBm4DjvLWLNB3MrdRf5nNlcQ/y8nUqg1MQDLE0Pcyt1F/mcwUZeoOc5PeSPJzksST3Jzmvm78xSSXZ00wXN+utTnJtt94jSS4adm0rzKkMzkOSnsWM9pq5XeHMZ6+ZzxVk6KdYJNkM/E1V7UuyCbgd+B7gSwzOpTmiqp5eYL0rgO9gcP7MCxl8G825VXXrUAuUVjgzKvWX+ZT6Yeh7kKtqW1Xtm3vaTSctYtU3A5dV1c6quhe4Gjh32PVJK50ZlfrLfEr9MJL7ICd5N4NgPo/B1x7+MXBsN7w9SQH/E/i5qno0yXrgeAa3N5lzN/CGBbZ9AXABwFFHHXXqpk2bRvErSFPhrrvuerSqNhzsemZUGo9Dyego89lt34xKnf1ldGR3sUhyOPAvgFcBvwqsBjYxuG3KMcBvA2ur6owk3wA8CDyvqp7s1v9u4Oqq2ri/15iZmanZ2dmR1C9NgyR3VdXMIa5rRqURO9SMjiOfYEal/WV0ZHexqKpnqurPga8Hfqqq9lTVbFU9XVVfBC4EXptkLYPvLwdY12xiHfv/thlJS2RGpf4yn9JkjeM2b6tY+PypuV3Xh1XVTuBhYEszvoXB95JLGi0zKvWX+ZQmYKgNcpIXJHljkjVJDk9yBnA28PEkpyU5OclhSY4B3gXcXlW7utVvALYmWd9duXs+cN0w65NWOjMq9Zf5lPpj2HuQC/gp4CFgJ/DrwFur6iPAicCtDA753APsYxD8OZcADwDbgTuAK709jTR0ZlTqL/Mp9cRUf9W0FxdopVvKRXrjYEa10plRqd/GfpGeJEmSNI1skCVJkqSGDbIkSZLUsEGWJEmSGjbIkiRJUsMGWZIkSWrYIEuSJEkNG2RJkiSpYYMsSZIkNWyQJUmSpIYNsiRJktSwQZYkSZIaNsiSJElSwwZZkiRJatggS5IkSQ0bZEmSJKlhgyxJkiQ1bJAlSZKkhg2yJEmS1Bh6g5zk95I8nOSxJPcnOa8Ze02S+5I8nuS2JCc0Y6uTXNut90iSi4ZdmyQzKvWZ+ZT6YRR7kK8ANlbVOuD7gcuTnJrkWOBm4GLgaGAW+GCz3qXAi4ETgFcDP5/kdSOoT1rpzKjUX+ZT6oFVw95gVW1rn3bTScCpwLaq+hBAkkuBR5Nsqqr7gDcD51bVTmBnkquBc4Fbh12jtJKZUam/zKfUDyM5BznJu5M8DtwHPAz8MbAZuHtumaraCzwAbE6yHji+He8ebx5FfdJKZ0al/jKf0uSNpEGuqp8G1gKvZHBIaB+wBtg1b9Fd3XJrmufzx54lyQVJZpPM7tixY9ilSyuCGZX6a5T5BDMqLcbI7mJRVc9U1Z8DXw/8FLAHWDdvsXXA7m6MeeNzY/O3e1VVzVTVzIYNG4ZfuLRCmFGpv0aVz27bZlR6DuO4zdsqBudPbQO2zM1MctTc/O6cqYfb8e5xey6WpNEwo1J/mU9pAobaICd5QZI3JlmT5PAkZwBnAx8HPgy8NMlZSY4E3g58pru4AOAGYGuS9Uk2AecD1w2zPmmlM6NSf5lPqT+GvQe5GBwKegjYCfw68Naq+khV7QDOAt7ZjZ0GvLFZ9xIGFxxsB+4Arqwqr76VhsuMSv1lPqWeGOpt3roAn36A8Y8Bm/Yztg94SzdJGgEzKvWX+ZT6w6+aliRJkho2yJIkSVLDBlmSJElq2CBLkiRJDRtkSZIkqWGDLEmSJDVskCVJkqSGDbIkSZLUsEGWJEmSGjbIkiRJUsMGWZIkSWrYIEuSJEkNG2RJkiSpYYMsSZIkNWyQJUmSpIYNsiRJktSwQZYkSZIaNsiSJElSwwZZkiRJatggS5IkSY2hNshJVie5Jsn2JLuTfDrJmd3YxiSVZE8zXTxv3WuTPJbkkSQXDbM2SWZU6jPzKfXHqhFs7++B04EHgdcDv5/kW5plnl9VTy+w7qXAi4ETgBcCtyX5bFXdOuQapZXMjEr9ZT6lnhjqHuSq2ltVl1bV31XVV6rqj4DPA6cuYvU3A5dV1c6quhe4Gjh3mPVJK50ZlfrLfEr9MdJzkJMcB7wE2NbM3p7koSTvTXJst9x64Hjg7ma5u4HNC2zzgiSzSWZ37Ngxwuql5c+MSv01inx2y5tR6TmMrEFOcgRwI3B9Vd0HPAq8nMHhn1OBtd04wJru565mE7u6ZZ6lqq6qqpmqmtmwYcOoypeWPTMq9deo8glmVFqMYZ+DDECSw4D3AU8BFwJU1R5gtlvki0kuBB5OshbY081fBzzZPN49ivqklc6MSv1lPqXJG/oe5CQBrgGOA86qqi/vZ9Gaq6GqdgIPA1ua8S08+7CSpCEwo1J/mU+pH0ZxisV7gG8Cvq+qnpibmeS0JCcnOSzJMcC7gNurau6Q0A3A1iTrk2wCzgeuG0F90kpnRqX+Mp9SDwz7PsgnAD8BnAI80tyr8RzgROBWBod87gH2AWc3q18CPABsB+4ArvT2NNJwmVGpv8yn1B9DPQe5qrYDOcAi7z/AuvuAt3STpBEwo1J/mU+pP/yqaUmSJKlhgyxJkiQ1bJAlSZKkhg2yJEmS1LBBliRJkho2yJIkSVLDBlmSJElq2CBLkiRJDRtkSZIkqWGDLEmSJDVskCVJkqSGDbIkSZLUsEGWJEmSGjbIkiRJUsMGWZIkSWrYIEuSJEkNG2RJkiSpYYMsSZIkNWyQJUmSpMZQG+Qkq5Nck2R7kt1JPp3kzGb8NUnuS/J4ktuSnDBv3WuTPJbkkSQXDbM2SWZU6jPzKfXHsPcgrwL+Hjgd+DpgK/D7STYmORa4GbgYOBqYBT7YrHsp8GLgBODVwM8ned2Q65NWOjMq9Zf5lHpiUQ1ykt9JUkn+2QJjJyd5Ksm7qmpvVV1aVX9XVV+pqj8CPg+cCvwgsK2qPlRVTzII85Ykm7pNvRm4rKp2VtW9wNXAuUv/FSXNMaNSf5lPqT8Wuwf5k93Pb19g7DeBx4BL5g8kOQ54CbAN2AzcPTdWVXuBB4DNSdYDx7fj3ePNC2zzgiSzSWZ37NixyPIlLcSMSv01inx22zWj0nNYbIN8Z/fzWQ1yku8BzgTeXlU7540dAdwIXF9V9wFrgF3ztrsLWNuNMW98buxZquqqqpqpqpkNGzYssnxJ85lRqb9GlU8wo9JiLLZBvh/4R5oGuQvvbwD3AL/bLpzkMOB9wFPAhd3sPcC6edtdB+zuxpg3PjcmacjMqNRf5lOavEU1yFVVDPYizyRJN/tnGRz6eWtVPTO3bDd+DXAccFZVfbkb2gZsaZY7CjiJwTlVO4GH2/Hu8bZD+aUk7Z8ZlfrLfEr9cDB3sbiTwVW1Jyd5AYMraW+pqo/PW+49wDcB31dVTzTzPwy8NMlZSY4E3g58pjt0BHADsDXJ+u6ig/OB6w76N5L0XMyo1F/mU+qBg2mQ2wv1fhlYDfz7doHunow/AZwCPJJkTzedU1U7gLOAdwI7gdOANzarX8LggoPtwB3AlVV160H/RpL2y4xK/WU+pf5YdRDL/iXwFeA84BUMwve37QJVtR3IAuvOjX8M2LSfsX3AW7pJ0giYUam/zKfUH4veg1xVjwGfBV4J/AODv2IlSZKkZeVgv0nvL7ufv1hVXh0rSZKkZWfRDXJ3W7dXMfh6y+tHVZAkSZI0SQdzDvJ/AL4ROKe77ZskSZK07BywQU5yNHAG8K3AzwG/UVV3HmgdSZIkaZo91x7kM4CbGFyU95vA20ZekSRJkjRBB2yQq+r9wPvHVIskSZI0cQd7FwtJkiRpWbNBliRJkho2yJIkSVLDBlmSJElq2CBLkiRJDRtkSZIkqWGDLEmSJDVskCVJkqSGDbIkSZLUsEGWJEmSGjbIkiRJUsMGWZIkSWoMtUFOcmGS2ST7klzXzN+YpJLsaaaLm/HVSa5N8liSR5JcNMy6JA2YUanfzKjUD6uGvL0vAJcDZwDPW2D8+VX19ALzLwVeDJwAvBC4Lclnq+rWIdcnrXRmVOo3Myr1wFD3IFfVzVV1C/Clg1z1zcBlVbWzqu4FrgbOHWZtksyo1HdmVOqHcZ+DvD3JQ0nem+RYgCTrgeOBu5vl7gY2L7SBJBd0h59md+zYMfqKpZXFjEr9ZkalMRhXg/wo8HIGh35OBdYCN3Zja7qfu5rld3XLfJWquqqqZqpqZsOGDSMqV1pxzKjUb2ZUGqNhn4O8oKraA8x2T7+Y5ELg4SRrgT3d/HXAk83j3eOoTZIZlfrOjErjNanbvNXc61fVTuBhYEszvgXYNvaqJM0xo1K/mVFphIZ9m7dVSY4EDgcOT3JkN++0JCcnOSzJMcC7gNurau5w0A3A1iTrk2wCzgeuG2Ztksyo1HdmVOqHYe9B3go8AbwN+NHu8VbgROBWBod77gH2AWc3610CPABsB+4ArvTWNNJImFGp38yo1AOpqudeqqdmZmZqdnb2uReUlqkkd1XVzKTr2B8zqpXOjEr9tr+M+lXTkiRJUsMGWZIkSWrYIEuSJEkNG2RJkiSpYYMsSZIkNWyQJUmSpIYNsiRJktSwQZYkSZIaNsiSJElSwwZZkiRJatggS5IkSQ0bZEmSJKlhgyxJkiQ1bJAlSZKkhg2yJEmS1LBBliRJkho2yJIkSVLDBlmSJElq2CBLkiRJjaE2yEkuTDKbZF+S6+aNvSbJfUkeT3JbkhOasdVJrk3yWJJHklw0zLokDZhRqd/MqNQPw96D/AXgcuDadmaSY4GbgYuBo4FZ4IPNIpcCLwZOAF4N/HyS1w25NklmVOo7Myr1wFAb5Kq6uapuAb40b+gHgW1V9aGqepJBkLck2dSNvxm4rKp2VtW9wNXAucOsTZIZlfrOjEr9MK5zkDcDd889qaq9wAPA5iTrgePb8e7x5oU2lOSC7vDT7I4dO0ZYsrSimFGp38yoNEbjapDXALvmzdsFrO3GmDc+N/ZVquqqqpqpqpkNGzYMvVBphTKjUr+ZUWmMxtUg7wHWzZu3DtjdjTFvfG5M0niYUanfzKg0RuNqkLcBW+aeJDkKOInB+VQ7gYfb8e7xtjHVJsmMSn1nRqUxGvZt3lYlORI4HDg8yZFJVgEfBl6a5Kxu/O3AZ6rqvm7VG4CtSdZ3FxycD1w3zNokmVGp78yo1A/D3oO8FXgCeBvwo93jrVW1AzgLeCewEzgNeGOz3iUMLjbYDtwBXFlVtw65NklmVOo7Myr1QKpq0jUcspmZmZqdnZ10GdLEJLmrqmYmXcf+mFGtdGZU6rf9ZdSvmpYkSZIaNsiSJElSwwZZkiRJatggS5IkSQ0bZEmSJKlhgyxJkiQ1bJAlSZKkhg2yJEmS1LBBliRJkho2yJIkSVLDBlmSJElq2CBLkiRJDRtkSZIkqWGDLEmSJDVskCVJkqSGDbIkSZLUsEGWJEmSGjbIkiRJUsMGWZIkSWqMtUFOcnuSJ5Ps6abPNWNvSrI9yd4ktyQ5epy1STKjUt+ZUWk8JrEH+cKqWtNNJwMk2Qz8LvBjwHHA48C7J1CbJDMq9Z0ZlUZs1aQL6JwDfLSq/gwgycXAvUnWVtXuyZYmCTMq9Z0ZlYZoEnuQr0jyaJJPJHlVN28zcPfcAlX1APAU8JLxlyeteGZU6jczKo3YuBvkXwBOBF4EXAV8NMlJwBpg17xldwFr528gyQVJZpPM7tixY9T1SiuNGZX6zYxKYzDWBrmq/qKqdlfVvqq6HvgE8HpgD7Bu3uLrgK86LFRVV1XVTFXNbNiwYfRFSyuIGZX6zYxK4zHp27wVEGAbsGVuZpITgdXA/ROqS9KAGZX6zYxKIzC2i/SSPB84DbgDeBr4EeA7gZ8FjgA+meSVwKeAdwA3e2GBND5mVOo3MyqNzzjvYnEEcDmwCXgGuA94Q1XdD5DkJ4EbgWOAjwE/PsbaJJlRqe/MqDQmY2uQq2oH8PIDjN8E3DSueiQ9mxmV+s2MSuMz6XOQJUmSpF6xQZYkSZIaNsiSJElSwwZZkiRJatggS5IkSQ0bZEmSJKlhgyxJkiQ1bJAlSZKkhg2yJEmS1LBBliRJkho2yJIkSVLDBlmSJElq2CBLkiRJDRtkSZIkqWGDLEmSJDVskCVJkqSGDbIkSZLUsEGWJEmSGjbIkiRJUsMGWZIkSWr0qkFOcnSSDyfZm2R7kjcdaPm77oJkMEkaPTMq9dfB5hPMqLQ/qyZdwDy/DTwFHAecAvyPJHdX1baFFy++ht08xfNIVlE1tjqlleqgM3oku3iSdSQxo9JoHWQ+Ab7Canazj7UkmFGp05s9yEmOAs4CLq6qPVX158BHgB87wFo8xVrg8LHUKK1kh5rRJ/k6wN1T0igdWj4BDmMfa0dfoDRl+rQH+SXA01V1fzPvbuD0dqEkFwAXDJ4dA8w0Y3fdNeoiD8GxwKOTLuIArG9pJl3fCWN8reWY0Un/+y1G32u0vgMbV0YXlU8wo0NmfUs36RoXzGifGuQ1wGPz5u2CZ/9pW1VXAVcBJJmtenSGHhvUWL2t0fqWpu/1Ddmyy+g0/Pv1vUbr641F5RPM6DBZ39L1tcbenGIB7AHWzZu3Dtg9gVokfTUzKvWX+ZSGqE8N8v3AqiQvbuZtAQ5wcYGkMTKjUn+ZT2mIetMgV9Ve4GbgHUmOSvIK4AeA9x1gtavGUtzS9L1G61uavtc3NMs0o32vD/pfo/X1wCHmE/r//ljf0vS9Puhpjake3dMlydHAtcB3A18C3lZVN022KklzzKjUX+ZTGp5eNciSJEnSpPXmFAtJkiSpD2yQJUmSpMZUNsiH8n3zY6jp9iRPJtnTTZ9rxt7U1bk3yS3deWKjrufCJLNJ9iW5bt7Ya5Lcl+TxJLclOaEZW53k2iSPJXkkyUXjrC/JxiTVvI97klw8zvq617im+zfbneTTSc5sxif+/vWdGV1UPWb00Gszo0tkRp+zFvO5tPqmP6NVNXUT8H7ggwxujP4dDG6GvnnCNd0OnLfA/M0M7kP5nV29NwEfGEM9Pwi8AXgPcF0z/9ju/fph4EjgSuDOZvwK4H8B64FvAh4BXjfG+jYCBazaz3ojrw84Cri0q+Uw4Hu7f8ONfXn/+j6Z0UXVY0YPvTYzuvT30IweuBbzubT6pj6jYw/AkN70p4CXNPPeB/zKhOvaX7B/GbipeX5SV//aMdV1+bzwXAD873nv5xPApu75F4DXNuOXjfI/ogXqe65wj7W+5nU+A5zVt/evj5MZPei6zOhw6jSji3+vzOjiazKfw6t1qjI6jadY7O/75jdPqJ7WFUkeTfKJJK/q5m1mUB8AVfUA3X9M4y9vwXr2Ag8Am5OsB45vx5nce7s9yUNJ3pvkWIBJ1ZfkOAb/XtuYnvdvkszo0kzLZ8yMTi8zeuim5fPVm3x2rz11GZ3GBnnR3zc/Zr8AnAi8iMFNrz+a5CQG9e6at+wk6z1QPWua5/PHxuVR4OXACcCp3Wvf2I2Nvb4kR3Svf31V3Uf/378+MKNL0/fPmBmdfmb00PX989WrfML0ZnTVuF9wCHr5ffNV9RfN0+uTnA28nv7Ve6B69jTPn5w3NhZVtQeY7Z5+McmFwMNJ1o67viSHMTjs+BRwYTe71+9fT/TtMw+Y0WExo8tC3z7zwNRktNefrz7lE6Y7o9O4B3lavm++gDCoa8vczCQnAqsZ/B6TML+eoxicz7WtqnYCD7fjTP69nfsmm8PGWV+SANcAxwFnVdWXu6Fpe/8mwYwuzbR9xszo9DGjh27aPl8TyScsg4yO+6TnIZ3o/QEGV+AeBbyCCV99CzwfOIPB1ZirgHOAvQzOt9nM4FDWK7t6f4/xXLCyqqvnCgZ/vc3VtqF7v87q5v0qz7569FeAOxhcPbqJwQd1FFe47q++04CTGfzxdgyDq6xvm0B9vwPcCayZN78X71/fJzO6qJrM6NLqM6NLe//M6IHrMZ9Lr3GqMzqRIAzhTT8auKULz4PAmyZczwbgrxgcAvin7gPx3c34m7o69wJ/CBw9hpouZfCXYztd2o39K+A+BleN3g5sbNZbDVzb/Wf0ReCicdYHnA18vnuvHgZuAF44zvoYnLtVDA7v7Gmmc/ry/vV9MqOLqsmMHnptZnTp76EZPXA95nNp9U19RtMVI0mSJInpPAdZkiRJGhkbZEmSJKlhgyxJkiQ1bJAlSZKkhg2yJEmS1LBBliRJkho2yJIkSVLDBlmSJElq2CBLkiRJDRtkHVCS5yV5KMmDSVbPG/tvSZ5J8sZJ1SetdGZU6i/zOb1skHVAVfUEcAnwDcBPz81PcgXwb4F/V1UfmFB50opnRqX+Mp/TK1U16RrUc0kOB+4GXgCcCJwH/CZwSVW9Y5K1STKjUp+Zz+lkg6xFSfK9wEeBPwVeDfxWVf3MZKuSNMeMSv1lPqePDbIWLcmngJcBHwDeVPM+PEn+DfAzwCnAo1W1cdw1SiuZGZX6y3xOF89B1qIk+RFgS/d09/xgd3YCvwX80tgKkwSYUanPzOf0cQ+ynlOS1zI4NPRR4MvADwPfUlX37mf5NwD/xb9+pfEwo1J/mc/p5B5kHVCS04CbgU8A5wBbga8AV0yyLkkDZlTqL/M5vWyQtV9Jvhn4Y+B+4A1Vta+qHgCuAX4gySsmWqC0wplRqb/M53SzQdaCkvxz4E8YnBN1ZlU91gxfBjwB/NokapNkRqU+M5/Tb9WkC1A/VdWDDG5svtDYF4CvHW9FklpmVOov8zn9bJA1NN3N0I/opiQ5Eqiq2jfZyiSBGZX6zHz2iw2yhunHgPc2z58AtgMbJ1KNpPnMqNRf5rNHvM2bJEmS1PAiPUmSJKlhgyxJkiQ1bJAlSZKkhg2yJEmS1LBBliRJkho2yJIkSVLDBlmSJElq/D8u3kHL7ouxswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "theta = np.random.randn(2, 1)\n",
    "theta = np.squeeze(np.asarray(theta))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(131); plot_gradient_descent(theta, eta=0.02)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\n",
    "plt.subplot(133); plot_gradient_descent(theta, eta=0.5)\n",
    "\n",
    "save_fig(\"gradient_descent_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(X,y,eta):\n",
    "    theta_path_mgd = []\n",
    "    X_b = np.c_[np.ones((751, 1)), X]  # add x0 = 1 to each instance\n",
    "    m = len(X_b)\n",
    "    n_iterations = 50\n",
    "    minibatch_size = 31\n",
    "\n",
    "    np.random.seed(42)\n",
    "    theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "    t0, t1 = 200, 1000\n",
    "    def learning_schedule(t):\n",
    "        return t0 / (t + t1)\n",
    "\n",
    "    t = 0\n",
    "    for epoch in range(n_iterations):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        X_b_shuffled = X_b[shuffled_indices]\n",
    "        y_shuffled = y[shuffled_indices]\n",
    "        for i in range(0, m, minibatch_size):\n",
    "            t += 1\n",
    "            xi = X_b_shuffled[i:i+minibatch_size]\n",
    "            yi = y_shuffled[i:i+minibatch_size]\n",
    "            gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n",
    "            eta = learning_schedule(t)\n",
    "            theta = theta - eta * gradients\n",
    "            theta_path_mgd.append(theta)\n",
    "    theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-751-7687dd076f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mminibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-730-1f26bfcfaaec>\u001b[0m in \u001b[0;36mminibatch\u001b[0;34m(X, y, eta)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mshuffled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mX_b_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0my_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "minibatch(Xarr,yarr,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_example = 2 * np.random.rand(100, 1)\n",
    "y_example = 4 + 3 * X_example + np.random.randn(100, 1)\n",
    "y_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    " y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(X)\n",
    "X = [[i] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xarr = [[i] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarr = [[i] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'asarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-814-6af9c4ece40b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Xarr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'asarray'"
     ]
    }
   ],
   "source": [
    "type(Xarr)\n",
    "# Xarr\n",
    "Xarray = Xarr.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.93594753],\n",
       "       [0.17681645],\n",
       "       [1.58363568],\n",
       "       [1.17991179],\n",
       "       [0.96009193],\n",
       "       [0.84107156],\n",
       "       [1.56933653],\n",
       "       [1.27872271],\n",
       "       [1.61008934],\n",
       "       [1.80630212],\n",
       "       [1.23452742],\n",
       "       [1.96092545],\n",
       "       [1.2161757 ],\n",
       "       [1.27328864],\n",
       "       [1.10963122],\n",
       "       [0.18200418],\n",
       "       [1.45279407],\n",
       "       [1.09489261],\n",
       "       [0.90182089],\n",
       "       [1.82094256],\n",
       "       [0.5959189 ],\n",
       "       [1.04720455],\n",
       "       [1.39528374],\n",
       "       [1.59294355],\n",
       "       [0.91869362],\n",
       "       [1.68418283],\n",
       "       [1.53783548],\n",
       "       [0.13247196],\n",
       "       [0.09172253],\n",
       "       [1.24161137],\n",
       "       [0.69482682],\n",
       "       [0.41826158],\n",
       "       [1.15929987],\n",
       "       [0.68312642],\n",
       "       [1.07452683],\n",
       "       [0.92023832],\n",
       "       [1.16953221],\n",
       "       [0.80060098],\n",
       "       [1.39533515],\n",
       "       [0.36013454],\n",
       "       [1.39300293],\n",
       "       [0.82332243],\n",
       "       [1.74863521],\n",
       "       [1.03047211],\n",
       "       [1.9462207 ],\n",
       "       [1.20387079],\n",
       "       [0.44769813],\n",
       "       [1.64358127],\n",
       "       [0.69016526],\n",
       "       [0.69523843],\n",
       "       [0.06360936],\n",
       "       [1.09743062],\n",
       "       [1.06884701],\n",
       "       [0.71198297],\n",
       "       [1.78843453],\n",
       "       [0.2574968 ],\n",
       "       [0.66019903],\n",
       "       [0.64316553],\n",
       "       [0.18458117],\n",
       "       [0.96229079],\n",
       "       [1.37556943],\n",
       "       [1.02331403],\n",
       "       [0.31395537],\n",
       "       [0.75457193],\n",
       "       [0.00519005],\n",
       "       [1.73660221],\n",
       "       [0.16903402],\n",
       "       [1.19455616],\n",
       "       [1.97251399],\n",
       "       [1.07318129],\n",
       "       [1.84808352],\n",
       "       [0.47223307],\n",
       "       [1.51991082],\n",
       "       [1.06253151],\n",
       "       [1.44103212],\n",
       "       [0.12468273],\n",
       "       [0.29547818],\n",
       "       [0.26623386],\n",
       "       [1.37433101],\n",
       "       [1.68888135],\n",
       "       [1.49923246],\n",
       "       [0.06094431],\n",
       "       [1.73442996],\n",
       "       [0.70829334],\n",
       "       [0.79432767],\n",
       "       [0.20973833],\n",
       "       [1.47481041],\n",
       "       [0.36456776],\n",
       "       [1.12793018],\n",
       "       [1.68141997],\n",
       "       [0.17840866],\n",
       "       [1.07067113],\n",
       "       [0.46643282],\n",
       "       [0.68585373],\n",
       "       [0.94793988],\n",
       "       [0.71020861],\n",
       "       [1.29764568],\n",
       "       [0.9591642 ],\n",
       "       [1.16839897],\n",
       "       [1.47364495]])"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(X_example)\n",
    "X_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst = [[i] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for item in X:\n",
    "#     temp = np.array([item])\n",
    "X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_example[0,0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DAP3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
