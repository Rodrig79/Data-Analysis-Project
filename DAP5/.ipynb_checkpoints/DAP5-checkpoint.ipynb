{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2E1jbS4ZluC",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (3.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from seaborn) (3.3.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from seaborn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from seaborn) (1.18.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (7.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (0.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-plot in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (0.3.7)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-plot) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-plot) (0.23.2)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-plot) (3.3.1)\n",
      "Requirement already satisfied: joblib>=0.10 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-plot) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scipy>=0.9->scikit-plot) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from scikit-learn>=0.18->scikit-plot) (2.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2020.6.20)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from statsmodels) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.21 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from statsmodels) (1.1.1)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from statsmodels) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from h5py->keras) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow) (49.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.21.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#If you need to install in modules in jupyter notebook \n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "%pip install matplotlib \n",
    "%pip install seaborn \n",
    "%pip install graphviz\n",
    "%pip install scikit-plot   \n",
    "%pip install statsmodels   \n",
    "%pip install keras\n",
    "%pip install tensorflow\n",
    "\n",
    "#Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import datetime # Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Keras specific\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "import keras.backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import graphviz\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "# PROJECT_ROOT_DIR = \".\"\n",
    "# CHAPTER_ID = \"decision_trees\"\n",
    "# IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "# os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "# def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "\n",
    "#     path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "#     print(\"Saving figure\", fig_id)\n",
    "#     if tight_layout:\n",
    "#         plt.tight_layout()\n",
    "#     plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvsV2RSPapC6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#changes the output for the print statements\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import chain\n",
    "import operator \n",
    "#function for counting how many units within each layer and how many layers\n",
    "def count_units(model):\n",
    "  tot_out = 0\n",
    "  out_list = []\n",
    "  for lyr in model.layers:\n",
    "    if lyr.trainable:\n",
    "      # This is to tackle any layers that have the output shape as a list of tuples (e.g Input layer)\n",
    "      if isinstance(lyr.output_shape, list):\n",
    "        curr_out = reduce(operator.mul, chain(*[s[1:] for s in lyr.output_shape]), 1)\n",
    "      # This is to tackle other layers like Dense and Conv2D\n",
    "      elif isinstance(lyr.output_shape, tuple):\n",
    "        curr_out = reduce(operator.mul, lyr.output_shape[1:], 1)\n",
    "      else:\n",
    "        raise TypeError\n",
    "      tot_out += curr_out\n",
    "      out_list.append(curr_out)\n",
    "  print(\"Total number of output units:\",tot_out)\n",
    "  print(\"Output units in each layer as a list:\",out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtW9LfInZ_x2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Pull \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Rodrig79/Machine-Learning-Data-Analysis-Project/master/rawData/pokemon.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#Data Cleaning\n",
    "df = df[~df.Name.str.contains('Mega')] #removed pokemon with \"Mega\" in it\n",
    "df = df.drop(columns = [\"Name\",\"Type 1\",\"Type 2\",\"#\",\"Generation\"]) #Removed columns with names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>751.000000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.549769</td>\n",
       "      <td>0.269293</td>\n",
       "      <td>0.422104</td>\n",
       "      <td>0.311932</td>\n",
       "      <td>0.390072</td>\n",
       "      <td>0.304823</td>\n",
       "      <td>0.370040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.146666</td>\n",
       "      <td>0.101750</td>\n",
       "      <td>0.166225</td>\n",
       "      <td>0.128826</td>\n",
       "      <td>0.168133</td>\n",
       "      <td>0.119135</td>\n",
       "      <td>0.154698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.422078</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.295652</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.491667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total          HP      Attack     Defense     Sp. Atk     Sp. Def  \\\n",
       "count  751.000000  751.000000  751.000000  751.000000  751.000000  751.000000   \n",
       "mean   0.549769    0.269293    0.422104    0.311932    0.390072    0.304823     \n",
       "std    0.146666    0.101750    0.166225    0.128826    0.168133    0.119135     \n",
       "min    0.233766    0.003922    0.027778    0.021739    0.055556    0.086957     \n",
       "25%    0.422078    0.196078    0.305556    0.217391    0.250000    0.217391     \n",
       "50%    0.558442    0.254902    0.416667    0.295652    0.361111    0.282609     \n",
       "75%    0.649351    0.313725    0.527778    0.391304    0.500000    0.369565     \n",
       "max    1.000000    1.000000    1.000000    1.000000    1.000000    1.000000     \n",
       "\n",
       "            Speed  \n",
       "count  751.000000  \n",
       "mean   0.370040    \n",
       "std    0.154698    \n",
       "min    0.027778    \n",
       "25%    0.250000    \n",
       "50%    0.361111    \n",
       "75%    0.491667    \n",
       "max    1.000000    "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = ['Legendary']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 7)\n",
      "(226, 7)\n"
     ]
    }
   ],
   "source": [
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "count_classes = y_test.shape[1]\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepsPerEpoch(x_train,batch_size):\n",
    "    steps_per_epoch = int( np.ceil(x_train.shape[0] / batch_size) )\n",
    "    print(\"steps per epoch:\",steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def c_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "batch_size = 32\n",
    "model = KerasClassifier(build_fn=c_model, epochs=50, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.6114\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.9124\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 894us/step - loss: 0.5431 - accuracy: 0.9124\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.9124\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 789us/step - loss: 0.4154 - accuracy: 0.9124\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 958us/step - loss: 0.3612 - accuracy: 0.9124\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.9124\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 981us/step - loss: 0.3541 - accuracy: 0.9124\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 996us/step - loss: 0.3508 - accuracy: 0.9124\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.9124\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.9124\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 940us/step - loss: 0.3388 - accuracy: 0.9124\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 1000us/step - loss: 0.3332 - accuracy: 0.9124\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.9124\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.9124\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 990us/step - loss: 0.3101 - accuracy: 0.9124\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 902us/step - loss: 0.2987 - accuracy: 0.9124\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 983us/step - loss: 0.2873 - accuracy: 0.9124\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 961us/step - loss: 0.2751 - accuracy: 0.9124\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9124\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.9124\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.9124\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 930us/step - loss: 0.2224 - accuracy: 0.9143\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9200\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.9238\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9276\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 929us/step - loss: 0.1706 - accuracy: 0.9314\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 964us/step - loss: 0.1625 - accuracy: 0.9390\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 963us/step - loss: 0.1551 - accuracy: 0.9390\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9410\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.1401 - accuracy: 0.9429\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9448\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9524\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 882us/step - loss: 0.1287 - accuracy: 0.9448\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9581\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9524\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9676\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9524\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9562\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9638\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9505\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9562\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9657\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9695\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9714\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9619\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9733\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.9695\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a9ed220>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps per epoch: 17\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_341 (Dense)            (None, 32)                256       \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 818\n",
      "Trainable params: 818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Total number of output units: 50\n",
      "Output units in each layer as a list: [32, 16, 2]\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsPerEpoch(X_train,batch_size) \n",
    "print(model.model.summary())\n",
    "print(count_units(model.model))\n",
    "model.model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "42/42 [==============================] - 0s 812us/step - loss: 0.5513 - accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 0s 739us/step - loss: 0.3874 - accuracy: 0.9143\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 0s 700us/step - loss: 0.3618 - accuracy: 0.9143\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 0s 819us/step - loss: 0.3532 - accuracy: 0.9143\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 0s 748us/step - loss: 0.3452 - accuracy: 0.9143\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.9048\n",
      "Epoch 1/5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.9167\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.9167\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.9167\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 0s 968us/step - loss: 0.3343 - accuracy: 0.9167\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.9167\n",
      "11/11 [==============================] - 0s 996us/step - loss: 0.3640 - accuracy: 0.8952\n",
      "Epoch 1/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6881\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8976\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 0s 956us/step - loss: 0.3824 - accuracy: 0.8976\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8976\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 0s 905us/step - loss: 0.3609 - accuracy: 0.8976\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.2117 - accuracy: 0.9714\n",
      "Epoch 1/5\n",
      "42/42 [==============================] - 0s 904us/step - loss: 0.4392 - accuracy: 0.9262\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 0s 879us/step - loss: 0.3316 - accuracy: 0.9262\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.9262\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.9262\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.9262\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8571\n",
      "Epoch 1/5\n",
      "42/42 [==============================] - 0s 700us/step - loss: 0.6075 - accuracy: 0.6929\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 0s 871us/step - loss: 0.3956 - accuracy: 0.9071\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 0s 996us/step - loss: 0.3686 - accuracy: 0.9071\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 0s 1000us/step - loss: 0.3607 - accuracy: 0.9071\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 0s 934us/step - loss: 0.3460 - accuracy: 0.9071\n",
      "11/11 [==============================] - 0s 932us/step - loss: 0.2843 - accuracy: 0.9333\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.9143\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.9143\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.9143\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 961us/step - loss: 0.3463 - accuracy: 0.9143\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 801us/step - loss: 0.3335 - accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 740us/step - loss: 0.3201 - accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.9143\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 813us/step - loss: 0.2831 - accuracy: 0.9143\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 793us/step - loss: 0.2657 - accuracy: 0.9143\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 717us/step - loss: 0.2449 - accuracy: 0.9143\n",
      "11/11 [==============================] - 0s 639us/step - loss: 0.2516 - accuracy: 0.9048\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.7429\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.9167\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 965us/step - loss: 0.3260 - accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 831us/step - loss: 0.3152 - accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.9167\n",
      "11/11 [==============================] - 0s 817us/step - loss: 0.2838 - accuracy: 0.8952\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 734us/step - loss: 0.4599 - accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 734us/step - loss: 0.4076 - accuracy: 0.8976\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 840us/step - loss: 0.3931 - accuracy: 0.8976\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 793us/step - loss: 0.3784 - accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 760us/step - loss: 0.3620 - accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 760us/step - loss: 0.3446 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 901us/step - loss: 0.3248 - accuracy: 0.8976\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 913us/step - loss: 0.3040 - accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 897us/step - loss: 0.2834 - accuracy: 0.8976\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 914us/step - loss: 0.2651 - accuracy: 0.9024\n",
      "11/11 [==============================] - 0s 678us/step - loss: 0.1738 - accuracy: 0.9810\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 803us/step - loss: 0.5030 - accuracy: 0.9190\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 766us/step - loss: 0.3313 - accuracy: 0.9262\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 761us/step - loss: 0.3120 - accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 734us/step - loss: 0.3008 - accuracy: 0.9262\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 753us/step - loss: 0.2915 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 903us/step - loss: 0.2767 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 820us/step - loss: 0.2641 - accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 788us/step - loss: 0.2477 - accuracy: 0.9262\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 796us/step - loss: 0.2291 - accuracy: 0.9262\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9262\n",
      "11/11 [==============================] - 0s 744us/step - loss: 0.3464 - accuracy: 0.8571\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 705us/step - loss: 0.5207 - accuracy: 0.8762\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 826us/step - loss: 0.3922 - accuracy: 0.9071\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 792us/step - loss: 0.3795 - accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 944us/step - loss: 0.3713 - accuracy: 0.9071\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.9071\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 837us/step - loss: 0.3457 - accuracy: 0.9071\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 828us/step - loss: 0.3291 - accuracy: 0.9071\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 992us/step - loss: 0.3072 - accuracy: 0.9071\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 841us/step - loss: 0.2832 - accuracy: 0.9071\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 865us/step - loss: 0.2579 - accuracy: 0.9071\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.9333\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.9143\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 959us/step - loss: 0.3789 - accuracy: 0.9143\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 972us/step - loss: 0.3666 - accuracy: 0.9143\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.9143\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.9143\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 904us/step - loss: 0.3433 - accuracy: 0.9143\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 948us/step - loss: 0.3348 - accuracy: 0.9143\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 864us/step - loss: 0.3250 - accuracy: 0.9143\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 870us/step - loss: 0.3139 - accuracy: 0.9143\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 971us/step - loss: 0.3017 - accuracy: 0.9143\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.9143\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.9143\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.9167\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 796us/step - loss: 0.2141 - accuracy: 0.9214\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 815us/step - loss: 0.1950 - accuracy: 0.9262\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 822us/step - loss: 0.1856 - accuracy: 0.9262\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 860us/step - loss: 0.1683 - accuracy: 0.9286\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 909us/step - loss: 0.1623 - accuracy: 0.9429\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 780us/step - loss: 0.1545 - accuracy: 0.9476\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9476\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9476\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9452\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9476\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 893us/step - loss: 0.1162 - accuracy: 0.9643\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 811us/step - loss: 0.1179 - accuracy: 0.9524\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 740us/step - loss: 0.1141 - accuracy: 0.9548\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 731us/step - loss: 0.1081 - accuracy: 0.9595\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 877us/step - loss: 0.1017 - accuracy: 0.9571\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9524\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9524\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9619\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 895us/step - loss: 0.0891 - accuracy: 0.9571\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 943us/step - loss: 0.0895 - accuracy: 0.9571\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 941us/step - loss: 0.0832 - accuracy: 0.9643\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.9595\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 884us/step - loss: 0.0760 - accuracy: 0.9762\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9619\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 967us/step - loss: 0.0819 - accuracy: 0.9571\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 985us/step - loss: 0.0813 - accuracy: 0.9619\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 870us/step - loss: 0.0816 - accuracy: 0.9619\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 898us/step - loss: 0.0710 - accuracy: 0.9690\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 928us/step - loss: 0.0826 - accuracy: 0.9619\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 717us/step - loss: 0.0715 - accuracy: 0.9619\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 682us/step - loss: 0.0698 - accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 727us/step - loss: 0.0688 - accuracy: 0.9643\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 711us/step - loss: 0.0740 - accuracy: 0.9619\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 849us/step - loss: 0.0677 - accuracy: 0.9643\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 829us/step - loss: 0.0679 - accuracy: 0.9643\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9643\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9810\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.9167\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 947us/step - loss: 0.3754 - accuracy: 0.9167\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 992us/step - loss: 0.3503 - accuracy: 0.9167\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 833us/step - loss: 0.3450 - accuracy: 0.9167\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 892us/step - loss: 0.3382 - accuracy: 0.9167\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.9167\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 964us/step - loss: 0.3236 - accuracy: 0.9167\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 937us/step - loss: 0.3136 - accuracy: 0.9167\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 896us/step - loss: 0.3021 - accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 863us/step - loss: 0.2926 - accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 877us/step - loss: 0.2797 - accuracy: 0.9167\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 992us/step - loss: 0.2666 - accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 883us/step - loss: 0.2526 - accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 839us/step - loss: 0.2375 - accuracy: 0.9167\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 831us/step - loss: 0.2218 - accuracy: 0.9190\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 909us/step - loss: 0.2180 - accuracy: 0.9214\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 930us/step - loss: 0.1981 - accuracy: 0.9190\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 916us/step - loss: 0.1852 - accuracy: 0.9262\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9262\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 912us/step - loss: 0.1648 - accuracy: 0.9381\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 862us/step - loss: 0.1537 - accuracy: 0.9357\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 891us/step - loss: 0.1426 - accuracy: 0.9429\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 923us/step - loss: 0.1335 - accuracy: 0.9452\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 891us/step - loss: 0.1310 - accuracy: 0.9452\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 873us/step - loss: 0.1232 - accuracy: 0.9548\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 952us/step - loss: 0.1181 - accuracy: 0.9476\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 854us/step - loss: 0.1113 - accuracy: 0.9595\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 895us/step - loss: 0.1126 - accuracy: 0.9595\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9643\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 979us/step - loss: 0.1008 - accuracy: 0.9595\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 919us/step - loss: 0.0989 - accuracy: 0.9595\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 870us/step - loss: 0.0918 - accuracy: 0.9690\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 824us/step - loss: 0.0926 - accuracy: 0.9667\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 825us/step - loss: 0.0883 - accuracy: 0.9738\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 985us/step - loss: 0.0865 - accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 949us/step - loss: 0.0853 - accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 868us/step - loss: 0.0780 - accuracy: 0.9690\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 968us/step - loss: 0.0811 - accuracy: 0.9714\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.9714\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9690\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 925us/step - loss: 0.0753 - accuracy: 0.9738\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 936us/step - loss: 0.0707 - accuracy: 0.9738\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 955us/step - loss: 0.0705 - accuracy: 0.9714\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 897us/step - loss: 0.0745 - accuracy: 0.9714\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 830us/step - loss: 0.0693 - accuracy: 0.9738\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 775us/step - loss: 0.0686 - accuracy: 0.9714\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 913us/step - loss: 0.0667 - accuracy: 0.9762\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 808us/step - loss: 0.0714 - accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 863us/step - loss: 0.0656 - accuracy: 0.9690\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 951us/step - loss: 0.0654 - accuracy: 0.9714\n",
      "11/11 [==============================] - 0s 938us/step - loss: 0.0978 - accuracy: 0.9524\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6138 - accuracy: 0.7214\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 995us/step - loss: 0.4305 - accuracy: 0.8976\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 949us/step - loss: 0.3869 - accuracy: 0.8976\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 815us/step - loss: 0.3773 - accuracy: 0.8976\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 824us/step - loss: 0.3694 - accuracy: 0.8976\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8976\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8976\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 814us/step - loss: 0.3203 - accuracy: 0.8976\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 770us/step - loss: 0.2981 - accuracy: 0.8976\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 835us/step - loss: 0.2708 - accuracy: 0.9000\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 754us/step - loss: 0.2491 - accuracy: 0.9024\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 733us/step - loss: 0.2261 - accuracy: 0.9238\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9119\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9214\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9310\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 917us/step - loss: 0.1736 - accuracy: 0.9405\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 763us/step - loss: 0.1630 - accuracy: 0.9333\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 773us/step - loss: 0.1503 - accuracy: 0.9476\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 726us/step - loss: 0.1424 - accuracy: 0.9452\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 786us/step - loss: 0.1377 - accuracy: 0.9429\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 991us/step - loss: 0.1312 - accuracy: 0.9452\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9500\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9548\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 917us/step - loss: 0.1203 - accuracy: 0.9500\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 910us/step - loss: 0.1148 - accuracy: 0.9571\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 998us/step - loss: 0.1102 - accuracy: 0.9595\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 915us/step - loss: 0.1064 - accuracy: 0.9476\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 928us/step - loss: 0.1024 - accuracy: 0.9595\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 989us/step - loss: 0.1037 - accuracy: 0.9595\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 878us/step - loss: 0.0978 - accuracy: 0.9571\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 914us/step - loss: 0.0945 - accuracy: 0.9595\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 996us/step - loss: 0.0985 - accuracy: 0.9548\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 919us/step - loss: 0.0941 - accuracy: 0.9571\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9643\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9643\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 916us/step - loss: 0.0870 - accuracy: 0.9667\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9690\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 952us/step - loss: 0.0908 - accuracy: 0.9571\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9595\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 957us/step - loss: 0.0789 - accuracy: 0.9667\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 731us/step - loss: 0.0747 - accuracy: 0.9738\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 728us/step - loss: 0.0765 - accuracy: 0.9595\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 735us/step - loss: 0.0756 - accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 827us/step - loss: 0.0726 - accuracy: 0.9690\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 748us/step - loss: 0.0681 - accuracy: 0.9762\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 862us/step - loss: 0.0738 - accuracy: 0.9690\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 877us/step - loss: 0.0692 - accuracy: 0.9738\n",
      "11/11 [==============================] - 0s 969us/step - loss: 0.0196 - accuracy: 0.9905\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 738us/step - loss: 0.6468 - accuracy: 0.7381\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 818us/step - loss: 0.4621 - accuracy: 0.9262\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.9262\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.9262\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 998us/step - loss: 0.3132 - accuracy: 0.9262\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 952us/step - loss: 0.3064 - accuracy: 0.9262\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 894us/step - loss: 0.2944 - accuracy: 0.9262\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 899us/step - loss: 0.2862 - accuracy: 0.9262\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 827us/step - loss: 0.2792 - accuracy: 0.9262\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 858us/step - loss: 0.2666 - accuracy: 0.9262\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2563 - accuracy: 0.9262\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.9262\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 892us/step - loss: 0.2324 - accuracy: 0.9262\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 800us/step - loss: 0.2181 - accuracy: 0.9262\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 793us/step - loss: 0.2083 - accuracy: 0.9262\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 848us/step - loss: 0.1920 - accuracy: 0.9262\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 835us/step - loss: 0.1782 - accuracy: 0.9262\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 699us/step - loss: 0.1641 - accuracy: 0.9262\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 733us/step - loss: 0.1517 - accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 692us/step - loss: 0.1344 - accuracy: 0.9405\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 707us/step - loss: 0.1201 - accuracy: 0.9548\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 687us/step - loss: 0.1149 - accuracy: 0.9571\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 743us/step - loss: 0.1038 - accuracy: 0.9500\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 647us/step - loss: 0.0978 - accuracy: 0.9667\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 683us/step - loss: 0.0905 - accuracy: 0.9690\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 698us/step - loss: 0.0868 - accuracy: 0.9690\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 739us/step - loss: 0.0801 - accuracy: 0.9762\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 687us/step - loss: 0.0789 - accuracy: 0.9762\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 747us/step - loss: 0.0786 - accuracy: 0.9690\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 775us/step - loss: 0.0711 - accuracy: 0.9833\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 860us/step - loss: 0.0666 - accuracy: 0.9762\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 778us/step - loss: 0.0636 - accuracy: 0.9762\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 763us/step - loss: 0.0626 - accuracy: 0.9762\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 750us/step - loss: 0.0598 - accuracy: 0.9786\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 767us/step - loss: 0.0564 - accuracy: 0.9857\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 926us/step - loss: 0.0554 - accuracy: 0.9786\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 900us/step - loss: 0.0541 - accuracy: 0.9833\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 806us/step - loss: 0.0510 - accuracy: 0.9833\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 811us/step - loss: 0.0478 - accuracy: 0.9833\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9738\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 835us/step - loss: 0.0569 - accuracy: 0.9810\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 850us/step - loss: 0.0467 - accuracy: 0.9810\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 821us/step - loss: 0.0433 - accuracy: 0.9857\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 922us/step - loss: 0.0447 - accuracy: 0.9810\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 950us/step - loss: 0.0451 - accuracy: 0.9786\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9833\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 897us/step - loss: 0.0400 - accuracy: 0.9857\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 823us/step - loss: 0.0395 - accuracy: 0.9810\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 738us/step - loss: 0.0391 - accuracy: 0.9833\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 722us/step - loss: 0.0428 - accuracy: 0.9833\n",
      "11/11 [==============================] - 0s 698us/step - loss: 0.1713 - accuracy: 0.9143\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 0s 714us/step - loss: 0.4541 - accuracy: 0.9071\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 729us/step - loss: 0.3895 - accuracy: 0.9071\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 729us/step - loss: 0.3799 - accuracy: 0.9071\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 787us/step - loss: 0.3665 - accuracy: 0.9071\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 735us/step - loss: 0.3543 - accuracy: 0.9071\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 716us/step - loss: 0.3397 - accuracy: 0.9071\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 755us/step - loss: 0.3209 - accuracy: 0.9071\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 719us/step - loss: 0.3062 - accuracy: 0.9071\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 843us/step - loss: 0.2917 - accuracy: 0.9071\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 755us/step - loss: 0.2727 - accuracy: 0.9071\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 723us/step - loss: 0.2528 - accuracy: 0.9071\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 748us/step - loss: 0.2406 - accuracy: 0.9143\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 865us/step - loss: 0.2289 - accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 788us/step - loss: 0.2121 - accuracy: 0.9190\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 740us/step - loss: 0.2022 - accuracy: 0.9262\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 761us/step - loss: 0.1884 - accuracy: 0.9238\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 728us/step - loss: 0.1780 - accuracy: 0.9310\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 691us/step - loss: 0.1719 - accuracy: 0.9357\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 703us/step - loss: 0.1638 - accuracy: 0.9357\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 694us/step - loss: 0.1534 - accuracy: 0.9405\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 675us/step - loss: 0.1445 - accuracy: 0.9429\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 709us/step - loss: 0.1435 - accuracy: 0.9405\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 680us/step - loss: 0.1372 - accuracy: 0.9452\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 712us/step - loss: 0.1266 - accuracy: 0.9524\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 708us/step - loss: 0.1217 - accuracy: 0.9524\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 727us/step - loss: 0.1188 - accuracy: 0.9548\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 695us/step - loss: 0.1159 - accuracy: 0.9571\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 695us/step - loss: 0.1102 - accuracy: 0.9524\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 712us/step - loss: 0.1071 - accuracy: 0.9571\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 736us/step - loss: 0.1061 - accuracy: 0.9524\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 771us/step - loss: 0.1017 - accuracy: 0.9548\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 710us/step - loss: 0.0952 - accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 706us/step - loss: 0.0962 - accuracy: 0.9619\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 716us/step - loss: 0.0964 - accuracy: 0.9690\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 890us/step - loss: 0.0948 - accuracy: 0.9524\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 697us/step - loss: 0.0881 - accuracy: 0.9595\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 708us/step - loss: 0.0921 - accuracy: 0.9643\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 708us/step - loss: 0.0885 - accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 918us/step - loss: 0.0876 - accuracy: 0.9643\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 854us/step - loss: 0.0848 - accuracy: 0.9690\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 722us/step - loss: 0.0986 - accuracy: 0.9595\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 710us/step - loss: 0.0911 - accuracy: 0.9619\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 725us/step - loss: 0.0758 - accuracy: 0.9690\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 720us/step - loss: 0.0768 - accuracy: 0.9643\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 791us/step - loss: 0.0758 - accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 703us/step - loss: 0.0779 - accuracy: 0.9643\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 721us/step - loss: 0.0765 - accuracy: 0.9643\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 725us/step - loss: 0.0875 - accuracy: 0.9524\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 825us/step - loss: 0.0725 - accuracy: 0.9619\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 722us/step - loss: 0.0735 - accuracy: 0.9619\n",
      "11/11 [==============================] - 0s 651us/step - loss: 0.0341 - accuracy: 0.9905\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.8857\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 953us/step - loss: 0.4375 - accuracy: 0.9143\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 895us/step - loss: 0.3748 - accuracy: 0.9143\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 811us/step - loss: 0.3615 - accuracy: 0.9143\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 954us/step - loss: 0.3564 - accuracy: 0.9143\n",
      "6/6 [==============================] - 0s 725us/step - loss: 0.3692 - accuracy: 0.9048\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 732us/step - loss: 0.5392 - accuracy: 0.9167\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 855us/step - loss: 0.4029 - accuracy: 0.9167\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 863us/step - loss: 0.3533 - accuracy: 0.9167\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 745us/step - loss: 0.3422 - accuracy: 0.9167\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 881us/step - loss: 0.3369 - accuracy: 0.9167\n",
      "6/6 [==============================] - 0s 755us/step - loss: 0.4030 - accuracy: 0.8952\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 770us/step - loss: 0.6056 - accuracy: 0.8952\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 845us/step - loss: 0.5148 - accuracy: 0.8976\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8976\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 961us/step - loss: 0.4123 - accuracy: 0.8976\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 811us/step - loss: 0.4020 - accuracy: 0.8976\n",
      "6/6 [==============================] - 0s 794us/step - loss: 0.2303 - accuracy: 0.9714\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 729us/step - loss: 0.5936 - accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 893us/step - loss: 0.4339 - accuracy: 0.9262\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 869us/step - loss: 0.3544 - accuracy: 0.9262\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 769us/step - loss: 0.3346 - accuracy: 0.9262\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 851us/step - loss: 0.3252 - accuracy: 0.9262\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8571\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 0s 716us/step - loss: 0.6248 - accuracy: 0.7881\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 0s 820us/step - loss: 0.4640 - accuracy: 0.9071\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 0s 812us/step - loss: 0.3919 - accuracy: 0.9071\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 0s 877us/step - loss: 0.3667 - accuracy: 0.9071\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 0s 833us/step - loss: 0.3593 - accuracy: 0.9071\n",
      "6/6 [==============================] - 0s 862us/step - loss: 0.2989 - accuracy: 0.9333\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 773us/step - loss: 0.6481 - accuracy: 0.6690\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.9143\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 819us/step - loss: 0.3819 - accuracy: 0.9143\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 870us/step - loss: 0.3595 - accuracy: 0.9143\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 867us/step - loss: 0.3509 - accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 839us/step - loss: 0.3455 - accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 838us/step - loss: 0.3374 - accuracy: 0.9143\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 836us/step - loss: 0.3286 - accuracy: 0.9143\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 928us/step - loss: 0.3203 - accuracy: 0.9143\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.9143\n",
      "6/6 [==============================] - 0s 727us/step - loss: 0.3211 - accuracy: 0.9048\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 806us/step - loss: 0.6243 - accuracy: 0.7857\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.9167\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 963us/step - loss: 0.4003 - accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 886us/step - loss: 0.3582 - accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 880us/step - loss: 0.3487 - accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 822us/step - loss: 0.3424 - accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 883us/step - loss: 0.3356 - accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 807us/step - loss: 0.3285 - accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 957us/step - loss: 0.3136 - accuracy: 0.9167\n",
      "6/6 [==============================] - 0s 959us/step - loss: 0.3615 - accuracy: 0.8952\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 723us/step - loss: 0.5755 - accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 871us/step - loss: 0.4614 - accuracy: 0.8976\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8976\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 895us/step - loss: 0.3990 - accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 830us/step - loss: 0.3921 - accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 895us/step - loss: 0.3863 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 780us/step - loss: 0.3775 - accuracy: 0.8976\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 872us/step - loss: 0.3703 - accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 824us/step - loss: 0.3611 - accuracy: 0.8976\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8976\n",
      "6/6 [==============================] - 0s 829us/step - loss: 0.1902 - accuracy: 0.9714\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 708us/step - loss: 0.4717 - accuracy: 0.9262\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 860us/step - loss: 0.3701 - accuracy: 0.9262\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 794us/step - loss: 0.3463 - accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 847us/step - loss: 0.3366 - accuracy: 0.9262\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 806us/step - loss: 0.3313 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 799us/step - loss: 0.3199 - accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 880us/step - loss: 0.3154 - accuracy: 0.9262\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 765us/step - loss: 0.3094 - accuracy: 0.9262\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 852us/step - loss: 0.3035 - accuracy: 0.9262\n",
      "6/6 [==============================] - 0s 755us/step - loss: 0.4613 - accuracy: 0.8571\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 765us/step - loss: 0.5717 - accuracy: 0.9071\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 901us/step - loss: 0.4434 - accuracy: 0.9071\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 950us/step - loss: 0.3798 - accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 914us/step - loss: 0.3701 - accuracy: 0.9071\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 933us/step - loss: 0.3609 - accuracy: 0.9071\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 782us/step - loss: 0.3530 - accuracy: 0.9071\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 793us/step - loss: 0.3428 - accuracy: 0.9071\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 824us/step - loss: 0.3323 - accuracy: 0.9071\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.9071\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 963us/step - loss: 0.3120 - accuracy: 0.9071\n",
      "6/6 [==============================] - 0s 905us/step - loss: 0.2562 - accuracy: 0.9333\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 0s 813us/step - loss: 0.6220 - accuracy: 0.8571\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 925us/step - loss: 0.4994 - accuracy: 0.9143\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 913us/step - loss: 0.4150 - accuracy: 0.9143\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 785us/step - loss: 0.3755 - accuracy: 0.9143\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 845us/step - loss: 0.3639 - accuracy: 0.9143\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 904us/step - loss: 0.3591 - accuracy: 0.9143\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 816us/step - loss: 0.3537 - accuracy: 0.9143\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 829us/step - loss: 0.3470 - accuracy: 0.9143\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 813us/step - loss: 0.3410 - accuracy: 0.9143\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 822us/step - loss: 0.3369 - accuracy: 0.9143\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 907us/step - loss: 0.3284 - accuracy: 0.9143\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 850us/step - loss: 0.3219 - accuracy: 0.9143\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 978us/step - loss: 0.3117 - accuracy: 0.9143\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.9143\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.9143\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2847 - accuracy: 0.9143\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.9143\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.9143\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9143\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9143\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9143\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 892us/step - loss: 0.2206 - accuracy: 0.9143\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9143\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 914us/step - loss: 0.2111 - accuracy: 0.9190\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 982us/step - loss: 0.1960 - accuracy: 0.9190\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9190\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.9190\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 919us/step - loss: 0.1709 - accuracy: 0.9262\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9452\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 988us/step - loss: 0.1581 - accuracy: 0.9429\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 948us/step - loss: 0.1518 - accuracy: 0.9429\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9452\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9476\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9452\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9476\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9452\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9595\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 887us/step - loss: 0.1252 - accuracy: 0.9452\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 981us/step - loss: 0.1170 - accuracy: 0.9571\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 918us/step - loss: 0.1182 - accuracy: 0.9500\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 994us/step - loss: 0.1113 - accuracy: 0.9500\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 915us/step - loss: 0.1108 - accuracy: 0.9500\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 863us/step - loss: 0.1070 - accuracy: 0.9500\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 891us/step - loss: 0.1099 - accuracy: 0.9524\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 787us/step - loss: 0.1016 - accuracy: 0.9595\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 884us/step - loss: 0.1008 - accuracy: 0.9524\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 928us/step - loss: 0.0983 - accuracy: 0.9595\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 962us/step - loss: 0.0962 - accuracy: 0.9595\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 878us/step - loss: 0.0934 - accuracy: 0.9619\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 883us/step - loss: 0.0930 - accuracy: 0.9571\n",
      "6/6 [==============================] - 0s 864us/step - loss: 0.0902 - accuracy: 0.9714\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 0s 844us/step - loss: 0.6489 - accuracy: 0.7190\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 787us/step - loss: 0.4979 - accuracy: 0.9167\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 839us/step - loss: 0.3873 - accuracy: 0.9167\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 901us/step - loss: 0.3492 - accuracy: 0.9167\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 963us/step - loss: 0.3438 - accuracy: 0.9167\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 836us/step - loss: 0.3370 - accuracy: 0.9167\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.9167\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 888us/step - loss: 0.3248 - accuracy: 0.9167\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 856us/step - loss: 0.3110 - accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 835us/step - loss: 0.3046 - accuracy: 0.9167\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 860us/step - loss: 0.2863 - accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 863us/step - loss: 0.2763 - accuracy: 0.9167\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 888us/step - loss: 0.2678 - accuracy: 0.9167\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 889us/step - loss: 0.2540 - accuracy: 0.9167\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9167\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 929us/step - loss: 0.2312 - accuracy: 0.9190\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9190\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 921us/step - loss: 0.2090 - accuracy: 0.9214\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 814us/step - loss: 0.2029 - accuracy: 0.9214\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 868us/step - loss: 0.1870 - accuracy: 0.9238\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 894us/step - loss: 0.1804 - accuracy: 0.9310\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 904us/step - loss: 0.1700 - accuracy: 0.9286\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 912us/step - loss: 0.1614 - accuracy: 0.9357\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 913us/step - loss: 0.1543 - accuracy: 0.9333\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 821us/step - loss: 0.1474 - accuracy: 0.9429\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 823us/step - loss: 0.1408 - accuracy: 0.9405\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 820us/step - loss: 0.1376 - accuracy: 0.9452\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 819us/step - loss: 0.1326 - accuracy: 0.9476\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 811us/step - loss: 0.1242 - accuracy: 0.9476\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 812us/step - loss: 0.1240 - accuracy: 0.9548\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 915us/step - loss: 0.1186 - accuracy: 0.9452\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9571\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9619\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 941us/step - loss: 0.1150 - accuracy: 0.9500\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 821us/step - loss: 0.1122 - accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9619\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 860us/step - loss: 0.1003 - accuracy: 0.9548\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 800us/step - loss: 0.0921 - accuracy: 0.9643\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 958us/step - loss: 0.0905 - accuracy: 0.9619\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 914us/step - loss: 0.0863 - accuracy: 0.9643\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 838us/step - loss: 0.0883 - accuracy: 0.9643\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 844us/step - loss: 0.0838 - accuracy: 0.9595\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 891us/step - loss: 0.0815 - accuracy: 0.9714\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 839us/step - loss: 0.0783 - accuracy: 0.9714\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 770us/step - loss: 0.0757 - accuracy: 0.9690\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 843us/step - loss: 0.0762 - accuracy: 0.9643\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 844us/step - loss: 0.0737 - accuracy: 0.9714\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9524\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 0s 775us/step - loss: 0.5201 - accuracy: 0.8976\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 900us/step - loss: 0.4319 - accuracy: 0.8976\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 992us/step - loss: 0.4074 - accuracy: 0.8976\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8976\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8976\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 957us/step - loss: 0.3866 - accuracy: 0.8976\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 840us/step - loss: 0.3775 - accuracy: 0.8976\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 966us/step - loss: 0.3665 - accuracy: 0.8976\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 870us/step - loss: 0.3566 - accuracy: 0.8976\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 849us/step - loss: 0.3463 - accuracy: 0.8976\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 880us/step - loss: 0.3337 - accuracy: 0.8976\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 984us/step - loss: 0.3181 - accuracy: 0.8976\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.8976\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 916us/step - loss: 0.2892 - accuracy: 0.8976\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 877us/step - loss: 0.2721 - accuracy: 0.8976\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 829us/step - loss: 0.2543 - accuracy: 0.8976\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 843us/step - loss: 0.2359 - accuracy: 0.9000\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9048\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 841us/step - loss: 0.2040 - accuracy: 0.9071\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 889us/step - loss: 0.1965 - accuracy: 0.9214\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 880us/step - loss: 0.1877 - accuracy: 0.9119\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 840us/step - loss: 0.1749 - accuracy: 0.9333\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 745us/step - loss: 0.1681 - accuracy: 0.9286\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 843us/step - loss: 0.1586 - accuracy: 0.9357\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 841us/step - loss: 0.1504 - accuracy: 0.9476\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 857us/step - loss: 0.1465 - accuracy: 0.9500\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 822us/step - loss: 0.1391 - accuracy: 0.9476\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 844us/step - loss: 0.1452 - accuracy: 0.9500\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 821us/step - loss: 0.1322 - accuracy: 0.9405\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 843us/step - loss: 0.1270 - accuracy: 0.9524\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 947us/step - loss: 0.1235 - accuracy: 0.9595\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 844us/step - loss: 0.1218 - accuracy: 0.9476\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 769us/step - loss: 0.1168 - accuracy: 0.9571\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 846us/step - loss: 0.1122 - accuracy: 0.9500\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 796us/step - loss: 0.1100 - accuracy: 0.9524\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 841us/step - loss: 0.1065 - accuracy: 0.9548\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 778us/step - loss: 0.1038 - accuracy: 0.9595\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 852us/step - loss: 0.1048 - accuracy: 0.9548\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 822us/step - loss: 0.0979 - accuracy: 0.9619\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 909us/step - loss: 0.0958 - accuracy: 0.9571\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 810us/step - loss: 0.0941 - accuracy: 0.9643\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 850us/step - loss: 0.0929 - accuracy: 0.9595\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 836us/step - loss: 0.0919 - accuracy: 0.9619\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 865us/step - loss: 0.0918 - accuracy: 0.9548\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 907us/step - loss: 0.0876 - accuracy: 0.9619\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 864us/step - loss: 0.0875 - accuracy: 0.9595\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 922us/step - loss: 0.0850 - accuracy: 0.9595\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 841us/step - loss: 0.0823 - accuracy: 0.9619\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 791us/step - loss: 0.0849 - accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 810us/step - loss: 0.0861 - accuracy: 0.9643\n",
      "6/6 [==============================] - 0s 698us/step - loss: 0.0336 - accuracy: 0.9905\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 0s 716us/step - loss: 0.4566 - accuracy: 0.9262\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 837us/step - loss: 0.3618 - accuracy: 0.9262\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 812us/step - loss: 0.3393 - accuracy: 0.9262\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 881us/step - loss: 0.3305 - accuracy: 0.9262\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 818us/step - loss: 0.3252 - accuracy: 0.9262\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 803us/step - loss: 0.3154 - accuracy: 0.9262\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 764us/step - loss: 0.3063 - accuracy: 0.9262\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 828us/step - loss: 0.2965 - accuracy: 0.9262\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 820us/step - loss: 0.2863 - accuracy: 0.9262\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 831us/step - loss: 0.2760 - accuracy: 0.9262\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 818us/step - loss: 0.2631 - accuracy: 0.9262\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 816us/step - loss: 0.2509 - accuracy: 0.9262\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 864us/step - loss: 0.2417 - accuracy: 0.9262\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 913us/step - loss: 0.2256 - accuracy: 0.9262\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 946us/step - loss: 0.2129 - accuracy: 0.9262\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 814us/step - loss: 0.1972 - accuracy: 0.9262\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 836us/step - loss: 0.1857 - accuracy: 0.9262\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 737us/step - loss: 0.1742 - accuracy: 0.9262\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 902us/step - loss: 0.1687 - accuracy: 0.9262\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 853us/step - loss: 0.1542 - accuracy: 0.9310\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 802us/step - loss: 0.1448 - accuracy: 0.9357\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 803us/step - loss: 0.1345 - accuracy: 0.9381\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 828us/step - loss: 0.1306 - accuracy: 0.9429\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 800us/step - loss: 0.1208 - accuracy: 0.9524\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 909us/step - loss: 0.1166 - accuracy: 0.9452\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 961us/step - loss: 0.1098 - accuracy: 0.9619\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9619\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 855us/step - loss: 0.0944 - accuracy: 0.9619\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 843us/step - loss: 0.0908 - accuracy: 0.9690\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9714\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9810\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9786\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9762\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 970us/step - loss: 0.0752 - accuracy: 0.9714\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9690\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 967us/step - loss: 0.0708 - accuracy: 0.9762\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9714\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.9810\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9833\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9786\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 940us/step - loss: 0.0553 - accuracy: 0.9833\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9857\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9857\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 961us/step - loss: 0.0536 - accuracy: 0.9786\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9857\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 906us/step - loss: 0.0487 - accuracy: 0.9881\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 988us/step - loss: 0.0524 - accuracy: 0.9738\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9857\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9738\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 963us/step - loss: 0.0441 - accuracy: 0.9857\n",
      "6/6 [==============================] - 0s 916us/step - loss: 0.1665 - accuracy: 0.9333\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 0s 726us/step - loss: 0.5912 - accuracy: 0.9071\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 835us/step - loss: 0.4747 - accuracy: 0.9071\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 840us/step - loss: 0.4082 - accuracy: 0.9071\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 823us/step - loss: 0.3867 - accuracy: 0.9071\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 792us/step - loss: 0.3806 - accuracy: 0.9071\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 840us/step - loss: 0.3769 - accuracy: 0.9071\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 814us/step - loss: 0.3771 - accuracy: 0.9071\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 938us/step - loss: 0.3696 - accuracy: 0.9071\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 807us/step - loss: 0.3669 - accuracy: 0.9071\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 908us/step - loss: 0.3631 - accuracy: 0.9071\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 795us/step - loss: 0.3585 - accuracy: 0.9071\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 832us/step - loss: 0.3538 - accuracy: 0.9071\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 805us/step - loss: 0.3468 - accuracy: 0.9071\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 849us/step - loss: 0.3396 - accuracy: 0.9071\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 814us/step - loss: 0.3308 - accuracy: 0.9071\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 912us/step - loss: 0.3210 - accuracy: 0.9071\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.9071\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 879us/step - loss: 0.2961 - accuracy: 0.9071\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 866us/step - loss: 0.2812 - accuracy: 0.9071\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.9071\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.9071\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9095\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 914us/step - loss: 0.2192 - accuracy: 0.9071\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 862us/step - loss: 0.2102 - accuracy: 0.9167\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 776us/step - loss: 0.1920 - accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 850us/step - loss: 0.1817 - accuracy: 0.9214\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9286\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 859us/step - loss: 0.1602 - accuracy: 0.9310\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 993us/step - loss: 0.1555 - accuracy: 0.9357\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 961us/step - loss: 0.1505 - accuracy: 0.9429\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 786us/step - loss: 0.1412 - accuracy: 0.9429\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 779us/step - loss: 0.1335 - accuracy: 0.9452\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 827us/step - loss: 0.1267 - accuracy: 0.9381\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 796us/step - loss: 0.1248 - accuracy: 0.9595\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 800us/step - loss: 0.1199 - accuracy: 0.9524\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 839us/step - loss: 0.1142 - accuracy: 0.9571\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 834us/step - loss: 0.1108 - accuracy: 0.9595\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 860us/step - loss: 0.1114 - accuracy: 0.9524\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 774us/step - loss: 0.1064 - accuracy: 0.9595\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 908us/step - loss: 0.1018 - accuracy: 0.9714\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 826us/step - loss: 0.1031 - accuracy: 0.9619\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 792us/step - loss: 0.1069 - accuracy: 0.9548\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 746us/step - loss: 0.1000 - accuracy: 0.9595\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 884us/step - loss: 0.0923 - accuracy: 0.9714\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 767us/step - loss: 0.0937 - accuracy: 0.9619\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 824us/step - loss: 0.0881 - accuracy: 0.9643\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 812us/step - loss: 0.0900 - accuracy: 0.9643\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 809us/step - loss: 0.0870 - accuracy: 0.9619\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 800us/step - loss: 0.0835 - accuracy: 0.9714\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 841us/step - loss: 0.0872 - accuracy: 0.9667\n",
      "6/6 [==============================] - 0s 778us/step - loss: 0.0450 - accuracy: 0.9905\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 0s 833us/step - loss: 0.6264 - accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.9143\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.9143\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.9143\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.9143\n",
      "3/3 [==============================] - 0s 987us/step - loss: 0.3847 - accuracy: 0.9048\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 0s 867us/step - loss: 0.7984 - accuracy: 0.1333\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.7262\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.9119\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.9143\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.9167\n",
      "3/3 [==============================] - 0s 770us/step - loss: 0.4524 - accuracy: 0.8952\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7789 - accuracy: 0.1429\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.7714\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.8952\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.8976\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8976\n",
      "3/3 [==============================] - 0s 767us/step - loss: 0.3835 - accuracy: 0.9714\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 0s 903us/step - loss: 0.6518 - accuracy: 0.7286\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.9262\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.9262\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.9262\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.9262\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x138ca3820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 725us/step - loss: 0.4812 - accuracy: 0.8571\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.6857\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.9048\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.9071\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.9071\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.9071\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13af12430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 719us/step - loss: 0.4933 - accuracy: 0.9333\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7977 - accuracy: 0.0857\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7321 - accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.7286\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.9143\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.9143\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.9143\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.9143\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.9143\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b302430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.9048\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 822us/step - loss: 0.5121 - accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.9167\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 995us/step - loss: 0.3850 - accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 926us/step - loss: 0.3669 - accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.9167\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b4f1280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 714us/step - loss: 0.4210 - accuracy: 0.8952\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.7151 - accuracy: 0.3643\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.8976\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.8976\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8976\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8976\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8976\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b0c1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 741us/step - loss: 0.2224 - accuracy: 0.9714\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 909us/step - loss: 0.6515 - accuracy: 0.8333\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.9262\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.9262\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.9262\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.9262\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.9262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13a924ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 835us/step - loss: 0.5103 - accuracy: 0.8571\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 892us/step - loss: 0.6094 - accuracy: 0.9071\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.9071\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.9071\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.9071\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.9071\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.9071\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.9071\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3720 - accuracy: 0.9071\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.9071\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13b0c1040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 709us/step - loss: 0.3150 - accuracy: 0.9333\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 920us/step - loss: 0.7817 - accuracy: 0.0881\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.4357\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.9214\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.9143\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.9143\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.9143\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.9143\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.9143\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.9143\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.9143\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.9143\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 981us/step - loss: 0.3482 - accuracy: 0.9143\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.9143\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.9143\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.9143\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.9143\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.9143\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.9143\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.9143\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.9143\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.9143\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.9143\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.9143\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 994us/step - loss: 0.3011 - accuracy: 0.9143\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.9143\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.9143\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.9143\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.9143\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.9143\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9143\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.9143\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.9143\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9143\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.9143\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9143\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9143\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9214\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.9214\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9214\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 943us/step - loss: 0.1918 - accuracy: 0.9214\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9214\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9286\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9310\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.1695 - accuracy: 0.9333\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9357\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9429\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9429\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9452\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9429\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9452\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13af12af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 850us/step - loss: 0.1556 - accuracy: 0.9333\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 967us/step - loss: 0.5905 - accuracy: 0.9167\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.9167\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.9167\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.9167\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.9167\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.9167\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.9167\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.9167\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.9167\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.9167\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.9167\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.9167\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.9167\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.9167\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.9167\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3126 - accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.9167\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2916 - accuracy: 0.9167\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9167\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9167\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9167\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9190\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9190\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.9190\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9238\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9238\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9310\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9310\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9286\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9357\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9381\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9333\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9357\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9405\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9429\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9429\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13aeb5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9429\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 926us/step - loss: 0.6914 - accuracy: 0.5405\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.8976\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.8976\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8976\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8976\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8976\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8976\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 993us/step - loss: 0.4089 - accuracy: 0.8976\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8976\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8976\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8976\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8976\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8976\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8976\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8976\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8976\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8976\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8976\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8976\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8976\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8976\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8976\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8976\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8976\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8976\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8976\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8976\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8976\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8976\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.9000\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.9024\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9048\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.9048\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.9048\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9048\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9143\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9167\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9143\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9190\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9286\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9286\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9286\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9333\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9333\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9333\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9333\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9405\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9429\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13ad849d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 787us/step - loss: 0.0883 - accuracy: 0.9810\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 927us/step - loss: 0.8330 - accuracy: 0.0810\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.3762\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.8500\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.9262\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.9262\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.9262\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.9262\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.9262\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.9262\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.9262\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.9262\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.9262\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.9262\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.9262\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.9262\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.9262\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 978us/step - loss: 0.3239 - accuracy: 0.9262\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.9262\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.9262\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.9262\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.9262\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.9262\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.9262\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.9262\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.9262\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.9262\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.9262\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.9262\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.9262\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.9262\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.9262\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.9262\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 883us/step - loss: 0.2749 - accuracy: 0.9262\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2723 - accuracy: 0.9262\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.9262\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.9262\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.9262\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9262\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.9262\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9262\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9262\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 989us/step - loss: 0.2327 - accuracy: 0.9262\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9262\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9262\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9262\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.9262\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9262\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.9262\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9286\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9286\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13a4b6430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 729us/step - loss: 0.3330 - accuracy: 0.8667\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5999 - accuracy: 0.9071\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.9071\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.9071\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.9071\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.9071\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.9071\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.9071\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.9071\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.9071\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.9071\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.9071\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.9071\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.9071\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.9071\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.9071\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.9071\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.9071\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.9071\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.9071\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.9071\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.9071\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.9071\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.9071\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.9071\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.9071\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.9071\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.9071\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.9071\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.9071\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.9071\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.9071\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.9071\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 921us/step - loss: 0.3155 - accuracy: 0.9071\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.9071\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.9071\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.9071\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2915 - accuracy: 0.9071\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 926us/step - loss: 0.2863 - accuracy: 0.9071\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.9071\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.9071\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2690 - accuracy: 0.9071\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.9071\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.9071\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.9071\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9071\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9071\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9071\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9071\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9071\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.9071\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x13a63fe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9333\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 957us/step - loss: 0.6444 - accuracy: 0.9119\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.9143\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.9143\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.9143\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.9143\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x139051700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 719us/step - loss: 0.5121 - accuracy: 0.9048\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.5006 - accuracy: 0.9167\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9167\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.9167\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4093 - accuracy: 0.9167\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.9167\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x13a63fca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 815us/step - loss: 0.4380 - accuracy: 0.8952\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.8976\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8976\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8976\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8976\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8976\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13b1a5820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.9714\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.1929\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.8357\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.9262\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.9262\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.9262\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x139862a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 787us/step - loss: 0.5393 - accuracy: 0.8571\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7720 - accuracy: 0.0929\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.2405\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.8762\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 0.9071\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.9071\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x13b6188b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.9333\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 940us/step - loss: 0.6362 - accuracy: 0.9143\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5975 - accuracy: 0.9143\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.9143\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.9143\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.9143\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.9143\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.9143\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.9143\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13b71d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 717us/step - loss: 0.3882 - accuracy: 0.9048\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.9167\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.9167\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13ac92ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 748us/step - loss: 0.4066 - accuracy: 0.8952\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7762 - accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.3381\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.7952\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.8976\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.8976\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8976\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x139ee2af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 897us/step - loss: 0.4172 - accuracy: 0.9714\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.8095\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.9262\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.9262\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.9262\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.9262\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.9262\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x1398818b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 722us/step - loss: 0.4775 - accuracy: 0.8571\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5738\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.9071\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.9071\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.9071\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.9071\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.9071\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.9071\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.9071\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.9071\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13afac550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 762us/step - loss: 0.3653 - accuracy: 0.9333\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.3095\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.9143\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.9143\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.9143\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.9143\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.9143\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.9143\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.9143\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.9143\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.9143\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.9143\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.9143\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.9143\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.9143\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.9143\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.9143\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.9143\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.9143\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.9143\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.9143\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.9143\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.9143\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.9143\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.9143\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.9143\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.9143\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.9143\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.9143\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.9143\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.9143\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.9143\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.9143\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.9143\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.9143\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.9143\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.9143\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.9143\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.9143\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.9143\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.9143\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.9143\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.9143\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.9143\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9143\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9143\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.9143\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.2455 - accuracy: 0.9143\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.9143\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9143\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9143\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13a0b1dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9048\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8035 - accuracy: 0.0833\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7485 - accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7066 - accuracy: 0.2810\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.8262\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.9095\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.9143\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.9143\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.9167\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.9167\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.9167\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.9167\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.9167\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.9167\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.9167\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.9167\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.9167\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.9167\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.9167\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.9167\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.9167\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.9167\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.9167\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.9167\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.9167\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.9167\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.9167\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.9167\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.9167\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.9167\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 817us/step - loss: 0.3018 - accuracy: 0.9167\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.9167\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13a3db040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8952\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.6442 - accuracy: 0.8714\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.8976\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.8976\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.8976\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8976\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.8976\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8976\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8976\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8976\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8976\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8976\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8976\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8976\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8976\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8976\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8976\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8976\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8976\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8976\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8976\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8976\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8976\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8976\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8976\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8976\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8976\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8976\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8976\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8976\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8976\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8976\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8976\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8976\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 993us/step - loss: 0.3372 - accuracy: 0.8976\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8976\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8976\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8976\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8976\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8976\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.3137 - accuracy: 0.8976\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8976\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8976\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8976\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8976\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8976\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.8976\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.8976\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8976\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8976\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8976\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13ab6c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 888us/step - loss: 0.1584 - accuracy: 0.9714\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7747 - accuracy: 0.0738\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7257 - accuracy: 0.1357\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.7262\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.9190\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.9262\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.9262\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.9262\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.9262\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.9262\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.9262\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.9262\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.9262\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.9262\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.9262\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.9262\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.9262\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.9262\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.9262\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.9262\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.9262\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.9262\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.9262\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.9262\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.9262\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.9262\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.9262\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.9262\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.9262\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.9262\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.9262\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.9262\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.9262\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.9262\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.9262\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.9262\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.9262\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.9262\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.9262\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.9262\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9262\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.9262\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.9262\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.9262\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.9262\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.9262\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.9262\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.9262\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.9262\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.9262\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.9262\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13aeb3dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.8571\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5857\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.9071\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.9071\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.9071\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.9071\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.9071\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.9071\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.9071\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.9071\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9071\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.9071\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.9071\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.9071\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.9071\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.9071\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.9071\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.9071\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.9071\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.9071\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.9071\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.9071\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.9071\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.9071\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.9071\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.9071\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.9071\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.9071\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.9071\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.9071\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.9071\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.9071\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.9071\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.9071\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.9071\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.9071\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.9071\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.9071\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.9071\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.9071\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.9071\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.9071\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.9071\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.9071\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.9071\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.9071\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.9071\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.9071\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.9071\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.9071\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.9071\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x13af125e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.9333\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.9124\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 886us/step - loss: 0.3892 - accuracy: 0.9124\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 907us/step - loss: 0.3791 - accuracy: 0.9124\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 908us/step - loss: 0.3724 - accuracy: 0.9124\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 852us/step - loss: 0.3651 - accuracy: 0.9124\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.9124\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.9124\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3136 - accuracy: 0.9124\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.9124\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.9124\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.9124\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9124\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9143\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9200\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9276\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9314\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9371\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9448\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9429\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 894us/step - loss: 0.1243 - accuracy: 0.9524\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9543\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9524\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9562\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9581\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 920us/step - loss: 0.0975 - accuracy: 0.9695\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 984us/step - loss: 0.1016 - accuracy: 0.9619\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 847us/step - loss: 0.0896 - accuracy: 0.9638\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 880us/step - loss: 0.0852 - accuracy: 0.9657\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 954us/step - loss: 0.0861 - accuracy: 0.9714\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.0827 - accuracy: 0.9695\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 950us/step - loss: 0.0839 - accuracy: 0.9600\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9638\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9714\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9581\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9695\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9733\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9676\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9733\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9676\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9695\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9695\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9676\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9771\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9638\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 977us/step - loss: 0.0640 - accuracy: 0.9676\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9695\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9695\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9695\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 897us/step - loss: 0.0639 - accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x13accf280>,\n",
       "             param_grid={'batch_size': [10, 20, 50, 100],\n",
       "                         'epochs': [5, 10, 50]})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(build_fn=c_model)\n",
    "\n",
    "batch_sizes = [10, 20, 50, 100]\n",
    "epochs = [5, 10, 50]\n",
    "parameters = {'batch_size': batch_sizes, 'epochs': epochs}\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9676190495491028 {'batch_size': 20, 'epochs': 50}\n",
      "0.9123809576034546 {'batch_size': 10, 'epochs': 5}\n",
      "0.9142857193946838 {'batch_size': 10, 'epochs': 10}\n",
      "0.9657142877578735 {'batch_size': 10, 'epochs': 50}\n",
      "0.9123809576034546 {'batch_size': 20, 'epochs': 5}\n",
      "0.9123809576034546 {'batch_size': 20, 'epochs': 10}\n",
      "0.9676190495491028 {'batch_size': 20, 'epochs': 50}\n",
      "0.9123809576034546 {'batch_size': 50, 'epochs': 5}\n",
      "0.9123809576034546 {'batch_size': 50, 'epochs': 10}\n",
      "0.9314285755157471 {'batch_size': 50, 'epochs': 50}\n",
      "0.9123809576034546 {'batch_size': 100, 'epochs': 5}\n",
      "0.9123809576034546 {'batch_size': 100, 'epochs': 10}\n",
      "0.9123809576034546 {'batch_size': 100, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_, clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "parameters = clf.cv_results_['params']\n",
    "for mean, parammeter in zip(means, parameters):\n",
    "    print(mean, parammeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.9143\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.9143\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 977us/step - loss: 0.5909 - accuracy: 0.9143\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.9143\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.9143\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.9143\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.9143\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.9143\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.9143\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.9143\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 976us/step - loss: 0.4538 - accuracy: 0.9143\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.9143\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.9143\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.9143\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.9143\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.9143\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.9143\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.9143\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.9143\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.9143\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.9143\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.9143\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.9143\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.9143\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.9143\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.9143\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.9143\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.9143\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.9143\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.9143\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.9143\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.9143\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.9143\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.9143\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.9143\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.9143\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.9143\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.9143\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.9143\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.9143\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.9143\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.9143\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.9143\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.9143\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.9143\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.9143\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.9143\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.9143\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.9143\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9143\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-04ac2d9e96e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'activation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softplus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softsign'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hard_sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 score = scorer._score(cached_call, estimator,\n\u001b[0m\u001b[1;32m     88\u001b[0m                                       *args, **kwargs)\n\u001b[1;32m     89\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0m\u001b[1;32m    213\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \"\"\"\n\u001b[0;32m-> 1044\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \"\"\"\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1169\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1434\u001b[0m                                     pos_label)\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                          str(average_options))\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.5/libexec/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "def c_model(activation):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation=activation))\n",
    "    model.add(Dense(16, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=c_model, epochs=50, batch_size=32)\n",
    "parameters = {'activation':['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']}\n",
    "clf = GridSearchCV(model, parameters, scoring='f1')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9657142877578735 {'activation': 'linear'}\n",
      "0.9123809576034546 {'activation': 'softmax'}\n",
      "0.9219047665596009 {'activation': 'softplus'}\n",
      "0.9485714316368103 {'activation': 'softsign'}\n",
      "0.9561904788017273 {'activation': 'relu'}\n",
      "0.954285717010498 {'activation': 'tanh'}\n",
      "0.9123809576034546 {'activation': 'sigmoid'}\n",
      "0.9123809576034546 {'activation': 'hard_sigmoid'}\n",
      "0.9657142877578735 {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_, clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "parameters = clf.cv_results_['params']\n",
    "for mean, parammeter in zip(means, parameters):\n",
    "    print(mean, parammeter)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DAP3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
